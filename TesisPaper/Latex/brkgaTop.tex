
\chapter{BRKGA algorithm for the TOP}

En el presente capítulo ahondaremos en detalle la solución implementada para el \textit{Team Orienteering Problem}. La implementación se la puede dividir en 3 módulos importantes. Primero el decodificador, que como mencionamos en el capítulo BRKGA tiene la tarea de convertir un arreglo de enteros aleatorios en una solución válida del problema. Luego el algoritmo BRKGA, cuya implementación puede hacerce con total independencia del problema a resolver. Por último las heurísticas locales aplicadas en cada nueva generación a el mejor individuo de la población, al cual no se le hayan aplicado previamente. 

\bigskip

En el capítulo \textit{Resultados} se mostrara en detalle los resultados obtenidos de la versión final de la implementación sobre el benchmark de problemas de Chao y Tsiligirides \cite{IntancesChaoTsiligirides}. Se compararon los resultados con los obtenidos de los trabajos previos de Chao et al. \cite{ChaoGoldenWasil}, de Archetti et al. \cite{ArchettiHertzSperanza} y los de Tang and E. Miller-Hooks \cite{TangMillerHooks}. En este capítulo se utilizaran los resultados de tales trabajos previos para crear un índice de efectividad a modo de poder evaluar la efectividad de la solución generada por el modulo analizado.

\bigskip

Además contaré las dificultades encontradas y desiciones tomadas para llegar a soluciones más competitivas con los trabajos previos seleccionados. A modo de monitorear el progreso, primero se seleccionó un subconjunto diverso del benchmark de problemas de Chao y Tsiligirides \cite{IntancesChaoTsiligirides}. Luego, para cada versión de la implementación que fui generando, se les calculó su índice de efectividad. Tal índice lo definí de la siguiente manera:

\begin{equation*}
bestProfit(i) = Max(Profit(CGW(i)), Profit(AHS(i)), Profit(TMH(i)))
\end{equation*}
\begin{equation*}
efectividad(imp_{v.xyz}) = Profit(imp_{v.xyz}(i)) / bestProfit(i)
\end{equation*}

\bigskip

Donde $Profit(Implementacion_v.xyz(i))$ representa la ganancia de la mejor solución obtenida luego de ejecutar una cierta cantidad de veces la version $xyz$ para la intancia del problema $i$. Luego $Profit(CGW(i))$, $Profit(AHS(i)$, $Profit(TMH(i))$ representan la ganancia de las implementaciones de Chao et al., Archetti et al. y Tang Miller-Hooks respectivamente para la misma instancia $i$. El índice es simplemenete devidir la ganancia obtenida por la mejor ganancia encontrada por los trabajos previos seleccionados. Si el $efectividad(imp_{v.xyz}) = 1$, luego nuestra implementación habra generado una solución tan buena como los trabajos previos. Si $0.95 \leq efectividad(imp_{v.xyz}) < 1$, mi solución no sera tan buena pero considero que esta en un rango donde es  competitiva. A lo largo de todo el desarrollo, el objetivo fue maximizar el índice de efectividad sin tener certeza de llegar a buenas soluciones utlizando la heurística BRKGA.

\bigskip

Para cada uno de los siguientes modulos y submodulos, se mostraran su pseudocodigo y su índice de efectividad. El pseudocódigo utilizado sigue la sintaxis de c\#, el lenguaje en el cual implemente el desarrollo. El objetivo del pseudocodigo es meramente descriptivo, el método que representa puede ser implementado con ciertas variaciones que no viene al caso describir. Tales variaciones para no mostrar: variables de medición de tiempo, variables para monitorear estados, testing, manejo de excepciones, persistencia de resultados, etc. Ademas variaciones para ser mas ilutrativo de la funcionalidad. 

\section{Decodificador}

El decodificador debe generar una solución valida del problema dado un vector aleatorio de enteros y conociendo la instancia del problema (vehículos disponibles, clientes, tmax, etc). A modo El decodificador construye una solución valida asignando clientes a las rutas de los vehículos disponibles respetando tmax, su distancia maáxima de recorrido. El orden en que toma los clientes a asignar es clave y determina la solución resultante. Es ahí donde utilizaremos el vector aleatorio de enteros, el vector aleatorio de enteros marcara el orden en el cual se tomaran los clientes para asignarlos a una ruta. Por lo tánto el vector aleatorio de enteros tendrá una longitud equivalente a la cantidad de clientes del problema (vertices con beneficio mayor a cero).

\subsection{Orden de los clientes a considerar}

Dado una instacia de un problema con $n$ clientes y un vector de enteros aleatorio de tamaño $n$, un decoder genera una solución valida de un problema. El vector, en mi implementacion, es un vector de RandomKeys. Un $RandomKey$ tiene dos propiedades, el entero aleatorio llamado $Key$ y otro entero llamado $PositionIndex$. 

\bigskip

\begin{lstlisting} 
public class RandomKey
{        
	public int Key { get; private set; }
	public int PositionIndex { get; private set; }
}
\end{lstlisting}

\bigskip

El propositio de $PositionIndex$ es para mapear un Key con un Cliente. Existe un arreglo de clientes en el Mapa del problema. Los clientes siempre tienen la misma posicion y esa posicion es un entero en el intervalo $[0, \#Clientes-1]$. Luego para un vector de RandomKeys de tamaño $\#Clientes$ no existen dos RandomKeys con mismo valor de PositionIndex y todos los PositionIndex se encuentran en el itervalo $[0, \#Clientes-1]$. De forma que cada RandomKey matchea siempre con solo RandomKey. Luego se matchean los clientes con los randomKeys por su position index y se los ordena de forma ascendente por el Key aleatorio.

\bigskip

\begin{lstlisting} 
public List<Client> GetOrderedClients(List<RandomKey> randomKeys)
{        
	return randomKeys.OrderBy(r => r.Key).Select(r => Map.Clients[r.PositionIndex]);
}
\end{lstlisting}

\subsection{Decodificador simple}

El decodificador simple recibe como parametro el vector de enteros aleatorios y con eso genera los clientes ordenados. Luego por cada vehiculo, si el siguiente cliente se puede incluir en la ruta se incluye sino considera que la ruta esta completa y pasa al siguiente vehiculo. Un cliente $c_i$ se puede agregar a la ruta si al agregarlo no supera la distancia maxima permitida para la ruta. Sean $v$ vehiculo, $dMax$ la distancia maxima de $v$, $dAct$ la distancia actual de $v$, $f$ el destino final de la ruta, $c_u$ el ultimo cliente agregado a la ruta de $v$ y $c_i$ cliente a evaluar agregar a la ruta de $v$. Luego cree la funcion can visit que implementa la siguiente formula:

\bigskip

\( dAct\, +\, distancia(c_u, c_i)\, +\, distancia(c_i, f)\, -\, distancia(c_u, f) \leq dMax\)

\bigskip

Pseudocodigo del metodo decode del decodificador simple:

\bigskip

\begin{lstlisting} 
public Solution Decode(List<RandomKey> randomKeys, ProblemInfo pi)
{
	var clients = GetOrderedClients(randomKeys);
	var vehicles = pi.GetVehicles();	
	var iv = 0;
	var ic = 0;	
	do
	{
		if(vehicles[iv].CanVisit(clients[ic]))
		{
			vehicles[iv].AddClient(clients[ic]);
			ic++;
		}
		else
		{
			iv++;			
		}
		
	} while(iv < vehicles.Length && ic < clients.Length)	
	var solution = pi.InstanceSolution(vehicles);
	return problem;
}
\end{lstlisting}

\bigskip

TODO Indice de efectividad

\subsection{Caracteristicas y debilidades del decodificador simple}

Tiene un orden de complejidad de $O(\#clientes)$.

\bigskip

Sea $v$ el vector de clientes ordenados por un vector aleatorio de enteros. Existen $m+1$ indices $i_0 = 0, i_1, i_2, .., i_m$ donde $m$ es la cantidad de vehículos y $0 \leq i_j \leq \#clientes$ tales que el vehículo $j$ incluye en su recorrido a todos los clientes del subvector $v[i_{j-1}, i_j-1]$. Luego todos los clientes en el subvector $v[i_m, v.Length - 1]$ son clientes no alcanzados por la solucion.

\bigskip

Un problema que tiene este decodificar es en la existencia de un cliente inalcansable, es decir si existe $c$ cliente tal que:

\( distancia(i, c)\, +\, distancia(c, f)\, >\, dMax\)

Esto puede generar soluciones de la poblacion donde existan vehiculos con rutas vacias. La solucion facil a este problema es filtrando todos los clientes inalcansables previo a la ejecucion del BRKGA.

\bigskip

Otro problema que tiene este decodificador es que cambia de vehiculo al primer intento fallido de expandir su ruta. Luego puede generar soluciones con rutas muy pequeñas, por este motivo implemente un Decodificador Goloso.

\bigskip

TODO Imagen de un vector de cuadrados pintados con colores segun a que vehiculo pertenece el cliente.

\subsection{Decodificador Goloso}

El decodificador goloso en principio funciona igual que el decodificador simple hasta que llega a un cliente que no pudo agregar a la ruta de un vehículo. En este caso, en vez de pasar a trabajar con el siguiente vehículo disponible, intenta agregar al siguiente cliente y así sucesivamente hasta que no hay mas clientes que intentar. Luego al pasar al siguiene vehiculo intenta solamente con los clientes no asignadas a los vehículos anteriores y siempre respetando el orden de los clientes asignado por el vector de enteros aleatorios.

\bigskip

\begin{lstlisting} 
public Solution Decode(List<RandomKey> randomKeys, ProblemInfo pi)
{
	var clients = GetOrderedClients(randomKeys);
	var cIterator = new Iterator(cliets);
	var vehicles = pi.GetVehicles();	
	var iv = 0;
	while(iv < vehicles.Length)
	{
		while(!cIterator.IsEmpty)
		{
			if(vehicles[iv].CanVisit(cIterator.Current))
			{
				vehicles[iv].AddClient(cIterator.Current);
				cIterator.RemoveCurrent;
			}
			else
			{
				cIterator.Next;			
			}			
		}
	}
	var solution = pi.InstanceSolution(vehicles);
	return problem;
}
\end{lstlisting}

\bigskip

Con esta modificación su orden complejidad aumenta a $0(\#clientes * \#vehiculos)$. De todos modos la cantidad de vehículos en todas las intancias del becnhmark utilizado siempre son menores o iguales a 4, luego no tiene un impacto en su performance. En promedio aumenta el profit de las soluciones generadas por el decodificador.

\bigskip

TODO Indice de efectividad

\section{BRKGA}

\subsection{Macro}

En una primera intancia se implementa un BRKGA estandar. Dado una instancia de un problema, primero se genera la población inicial. Luego mientras no se cumpla la condición de parada, evolucionamos la poblacion. Es decir generamos una nueva generacion de soluciones a partir de la generación anterior como se explico en la sección BRKGA ~(ver sección~\ref{sec:brkga}).

\bigskip

Pseudocódigo de una vista macro general del algoritmo BRKGA implementado.

\bigskip

\begin{minipage}{\textwidth}
\begin{lstlisting} 
public Solution RunBrkga(ProblemManager problemManager)
{
    ProblemManager.InitializePopulation();

    while (!ProblemManager.StoppingRuleFulfilled())
        ProblemManager.EvolvePopulation();

    return ProblemManager.Population.GetMostProfitableSolution();
}
\end{lstlisting}
\end{minipage}

\bigskip

El objeto ProblemManager es el orquestrador del mi BRKGA, se setea con un objeto Configuración y el objeto PopulationGenerator. Tiene acceso de forma indirecta, atravéz de PopulationGenerator, de toda la información del problema (vehículos, clientes, tmax, etc.).

\subsection{Configuración}

A modo de poder testear distintas configuraciones del BRKGA, se creo un objeto $Configuration$ que setea todas las configuraciones que impactan en el resultado final del BRKGA. Este objeto es esencial para tunear el implementacion de una forma rápida y ordenada. Al centralizar todas las variables que podrían impactar en resultado final, ganaba mucho tiempo en al testear variaciones de mi implementación. Además, al estar centralizada toda la información variable se obtiene una lectura veloz del BRKGA que se esta usando. En otras palabras incrementamos nuestra capacidad de monitoreo y control de mi implementación.

\bigskip

\begin{minipage}{\textwidth}
\begin{lstlisting}
public class BrkgaConfiguration
{
	public string Description { get; }
	public int MinIterations { get; set; }
	public int MinNoChanges { get; set; }
	public int PopulationSize { get; set; }
	public decimal ElitePercentage { get; set; }
	public decimal MutantPercentage { get; set; }
	public int EliteGenChance { get; set; }
	public List<ILocalSearchHeuristic> Heuristics { get; set; }
	public int ApplyHeuristicsToTop { get; set; }
	public DecoderEnum DecoderType { get; set; }
	
	private void SetDescription();
}
\end{lstlisting}
\end{minipage}

\bigskip

\begin{minipage}{\textwidth}
Descripción de las propiedades del objeto Configuración:

\begin{itemize}
  \item \textbf{Description}: Es una especie de hash descriptivo de la instancia del objeto. Su funcionalidad es poder identificar rápidamente la configuración global del BRKGA. Solo puede ser seteado con el metodo SetDescription() que utilza la clave y el valor de el resto de las propiedades.
  \item \textbf{MinIterations}: Clave \textbf{MI}. Valor entero utilizado en la función de corte. Cantidad mínima de generaciones que debe genererar el BRKGA para finalizar. 
  \item \textbf{MinNoChanges}: Clave \textbf{MNC}. Valor entero utilizado en la función de corte. Cantidad de generaciones sin modificaciones del mejor beneficio necesario para cortar el algoritmo BRKGA.
  \item \textbf{PopulationSize}: Clave \textbf{PS}. Valor entero denota el tamaño de la población.
  \item \textbf{ElitePercentage}: Clave \textbf{EP}. Valor decimal en el itervalo $(0, 1)$ que determina el tamaño de la poblacion elite. 
  \item \textbf{MutantPercentage}: Clave \textbf{MP}. Valor decimal en el itervalo $(0, 1)$ que determina el tamaño mínimo de la poblacion mutante. 
  \item \textbf{EliteGenChance}: Clave \textbf{EGC}. Valor entero en el intervalo $(0, 100)$ que determina la probabilidad que tiene un key del padre elite, en transmitirse a su descendiente. 
  \item \textbf{Heuristics}: Clave \textbf{HEU}. Secuencia de heuristicas de busqueda local que se le aplicaran a la mejor solución de cada generación, a la cual no se le hayan aplicado las heuristicas locales aún. Se implementaron cuatro heuristicas locales:
	\begin{itemize}
		\item \textbf{Swap}: Valor \textbf{S}.
		\item \textbf{Insert}: Valor \textbf{I}.
		\item \textbf{2-Opt}: Valor \textbf{O}.
		\item \textbf{Replace}: Valor \textbf{R}.
	\end{itemize}  
  \item \textbf{ApplyHeuristicsToTop}: Clave \textbf{TOP}. Valor entero que denota la cantidad de soluciones a las cuales se les aplicaran las heuristicas de busqueda local.
  \item \textbf{DecoderType}: Clave \textbf{DT}. Es una enumeracion que determina el decoder que se va a utilizar.
	\begin{itemize}
		\item \textbf{Simple}: Valor \textbf{S}.
		\item \textbf{Goloso}: Valor \textbf{G}.
	\end{itemize}  
\end{itemize}
\end{minipage}

\bigskip

El método SetDescription() toma las tuplas de clave y valor de todas las propiedades del objeto configuration excepto Description y genera un string intercalando con un separador.

\begin{minipage}{\textwidth}
\begin{lstlisting} 
public void SetDescription()
{ 
	var prop = Properties.Where(x => x.Name != "Description");
	var claveValores = prop.Select(p => p.Clave + "." + p.Valor);
	Description = string.Join(";", claveValores);
}
\end{lstlisting}
\end{minipage}


\begin{minipage}{\textwidth}
Luego dado un description podemos ver como esta configurado el BRKGA.

Ej: "MI.200;MNC.10;PZ.100;EP.0,3;MP.0,1;EGC.70;HEU.ISIRT;TOP.2;DT.G"

\begin{itemize}
  \item MinIterations: 200
  \item MinNoChanges: 10
  \item PopulationSize: 100
  \item ElitePercentage: 0,3
  \item MutantPercentage: 0,1
  \item EliteGenChance: 70
  \item Heuristics: ISIRT. Que es la Secuencia Insert, Swap, Insert, Replace, 2-Opt.
  \item ApplyHeuristicsToTop: 2
  \item DecoderType: Decodificador Goloso
\end{itemize}
\end{minipage}

\subsection{Inicialización de la Población}

Utilizando $PopulationSize$ del objeto $Configuration$ seteo el tamaña de la población. Luego para generar la población inicial se genereran $PopulationSize$ vectores de enteros aleatorios de tamaño $\#clientes$ de la instancia del problema. Este conjunto de vectores se lo pasa como argumento al decodificador, quien genere un individuo por cada vector de enteros aleatorios.

\subsection{Condición de parada}

En un principio la condición de parada era simple, el bucle terminaba cuando iteraba una $x$ cantidad de veces seteado en el objeto $Configurations$ por $MinIerations$. Es decir que el bucle principal cortaba luego de evolucionar la poblacion $MinIerations$ veces. Luego de analizar las últimas generaciones de la solución y ver que era frecuente que la mejor solución se habia generado recientemente, agregue una condicion de corte adicional. Ahora, para cortar ademas de la condición anterior, el beneficio de la mejor solución no debería haberse modificado durante las últimas $n$ generaciones . Es decir durante las últimas $n$ genereciones no debe haber aparecido una nueva mejor solución. Este valor es ajustable desde la propiedad $MinNoChanges$ del objeto $Configurations$.

\bigskip

\begin{minipage}{\textwidth}
\begin{lstlisting} 
public bool StoppingRuleFulfilled()
{ 
    return GenerationNum >= MinIterations && NoChanges();
}
private bool NoChanges()
{
	var currentProfit = CurrentBestSolution.GetProfit();
	return LastProfits.All(p => p == currentProfit);
}
\end{lstlisting}
\end{minipage}

\subsection{Evolución de la población}

Se toma la población y se los ordena descendientemente segun su beneficio calculado por la función objetivo. Se setea la población de elite y la non-elite. La población de elite son los mejores $x$ individuos de la población. Siendo $x$ un porcentaje de la población total seteado con la propiedad $ElitePercentage$ del objeto $Configuration$. La población non-elite son todos aquellos individuos no incluídos en la población de elite. Luego se generan $y$ individuos mutantes, $y$ es un porcentaje de la población total seteado por la propiedad $MutantPercentage$. Pasan a la nueva genereción todos los individuos de la población de elite y se agregan los de la población mutante. Finalmente se completa la nueva generación emparentando individuos de la población de elite con individuos de la población non-elite. Los padres son elegidos al azar y el proceso de apareamiento se realiza como se describe en el la sección BRKGA ~(ver sección~\ref{sec:brkga}). Durante el apareamiento, no es tan extraño que se genere una solución identica a otra ya existente en la población. De modo de no repetir soluciones, antes de insertar el individuo resultante se verifica que no exista otra solución idéntica en la nueva generación.

\bigskip

\begin{minipage}{\textwidth}
\begin{lstlisting}
public Population Evolve(Population population)
{
    var ordPopulation = population.GetOrderByMostProfitable();
    var elites = ordPopulation.Take(EliteSize);
    var nonElites = ordPopulation.Skip(EliteSize).Take(NonEliteSize);
    var mutatants = Generate(MutatansSize);
    var evolvedPopulation = new pop(elites, mutatants);
    while (evolvedPopulation.Size() < PopulationSize)
    {
		var anElite = GetRandomItem(elites);
		var aNoneElite = GetRandomItem(nonElites);
        var childSolution = Mate(anElite, aNoneElite);
        if (evolvedPopulation.Any(x => x.Equals(childSolution)))
            evolvedPopulation.Add(GenerateSolution());
        else
            evolvedPopulation.Add(childSolution);
    }
    return evolvedPopulation;
}
\end{lstlisting}
\end{minipage}

\begin{minipage}{\textwidth}
\begin{lstlisting}
private Solution Mate(Solution eliteP, Solution nonEliteP)
{
	var childRandomKeys = new List<RandomKey>();
	for (var index = 0; index < eliteP.RandomKeys.Count; index ++)
	{
		int key = 0;
		if(Random.Next(100) >= EliteGenChance)
			key = eliteP.RandomKeys[index].Key;
		else
			key = nonEliteP.RandomKeys[index].Key;
		var randomKey = new RandomKey(key, index);
		childRandomKeys.Add(randomKey);
	}
	return Decoder.Decode(childRandomKeys, ProblemInfo);
}
\end{lstlisting}
\end{minipage}

\bigskip

Como mencioné anteriormente, los individuos mutantes son individuos generedos a partir de un vector de RandomKeys, del mismo modo que la población inicial. Con el fín de mostrar lo simple que es la generación de un nuevo vector de RandomKeys, presento el pseudocodigo del GenerateSolution que al final termina llamando al método decode del decoder descripto anteriormente.

\bigskip

\begin{minipage}{\textwidth}
\begin{lstlisting}
private Solution GenerateSolution()()
{
	var randomKeys = new List<RandomKey>();
	for(i = 0; i < ProblemInfo.Clients.Length; i++)
	{
		var key = Random.Next(1000);
		var randomKey = new RandomKey(key, index);
		randomKeys.Add(randomKey)
	}
	return Decoder.Decode(randomKeys, ProblemInfo);
}
\end{lstlisting}
\end{minipage}

\bigskip

Verificar que dos soluciones son iguales tiene un costo muy bajo en BRKGA. Esto se debe a que el decodificador es un algoritmo deterministico. Por lo tanto para dos vectores de RandomKeys cuyo orden de clientes que genere sea el mismo, el decodificador generará la misma solución. Luego lo unico que hay que comparar es el hash de ambas soluciones y esto se puede hacer en $O(1)$. El hash de una solución, se calcula una sola vez cuando se construye la solución a partir de su vector de RandomKey. El hash es una concatenación de la propiedad PositionIndex de cada RandomKey en el vector ordenados por la propiedad Key, itercalados con un separador. Es decir, es el orden de la cuidades que toma el decoder intercalados con un separador. Si ya existe un individuo con el mismo hash, se genera una solución mutante y continua el apareamiento de otros dos individuos. Decidí no reintentar el apareamiento entre los dos padres que genereron la solución ya existente, porque consideré que la probabilidad de volver a generar nuevamente una solución existente es alta. Ademas, aún si en un segundo intento no generera una solución idéntica a alguna de la nueva población, lo más seguro que la solución originada se muy cercana a una existente. Luego tome esta desición para optimizar el apareamiento y disminuir soluciones dentro de un mismo vecindario por genereración.

\bigskip

\begin{minipage}{\textwidth}
\begin{lstlisting}
private string pseudoHash;
public string GetHash()
{
	if (!string.IsNullOrEmpty(pseudoHash))
		return pseudoHash;
		
	var ork = RandomKeys.OrderBy(r => r.Key)
	pseudoHash = string.Join("@", ork.Select(k => k.PositionIndex));
	return pseudoHash;
}
\end{lstlisting}
\end{minipage}

\bigskip

En una primera instancia se insertaban los individuos sin verificar que la solución no existiese en la población. Dado una población de soluciones no repetidas, la probabilidad de de generar una solucion existente al evolucionar la población, es baja. Aún así, una vez que sucede, la probabilidad de generar otra más aumenta considerablemente ya que ahora hay mas probabilidades de utilizar padres ídenticos. Si además la solución repetida se ecuentra dentro del subconjunto de elite, la probabilidad aumenta aún más. Esto generaba un efecto bola de nieve donde cada nueva generación tenía cada vez más individuos repetidos. Incluso se llego al caso donde toda una población constituía de una unica solución excepto por las soluciones mutantes. Esto reducía ampliamente la cantidad de soluciones diferentes exploradas, luego reducía fuertemente la frecuencia con la que una nueva mejor solución aparecía. Además si uno tiene varios individuos iguales en una solución, el algoritmo se vuelve menos eficiente ya que repite trabajo en donde obtiene los mismos resultados. Entonces el costo total de validar unicidad en la inserción, que conlleva un orden de complejidad $O(PopulationSize * NonElitePopulationSize)$, resulta muy bajo comparado con el costo de trabajar con multiples soluciones repetidas.

\subsection{Resultados de la primer versión}

La primer versión del BRKGA para TOP no incluía el objeto de configuración y permitía insertar soluciones repetidas en una misma generación. Los indices de efectividad que mostrare a continuación corresponden con una primera versión que no admitía repetidos y el objeto configuracion.

\bigskip

TODO Indice Efectividad para cada configuracion. (5-7 config).

\bigskip

TODO hablar sobre estos resultados parciales.

Para instancias de testeo pequeñas esta versión funcionaba tan bien como Chao, Golden y Wasil (CGW), Tang y Miller-Hooks (TMH) y Archetti, Hertz, Speranza (AHS). Desafotunadamente no sucedía lo mismo cuando aumentaban la cantidad de clientes y vehículos.

\section{Heuristicas de busqueda local}

En pos de optimizar los resultados mencionados anteriormente se implementaron heuristicas de busqueda local. La idea fue aplicar estas heurísticas a la mejores $x$ soluciónes de cada nueva generación. Donde $x$ toma el valor de la propiedad $ApplyHeuristicsToTop$. En caso de a la solución ya se le hubiese aplicado las heuristicas en una generación anterior, se aplican a la siguiente mejor solución. Esto puede suceder ya que las mejores soluciones pertenecen al conjunto de elite, y todos los indiviuos del conjunto de elite pasan a la siguiente generación.

\subsection{Swap (Entre rutas distintas)}

El objetivo de esta heuristica es encontrar e intercambiar clientes entre dos rutas distintas con el fin de disminuir la suma de las distancias recorridas de ambas rutas mientras sigan respetando la restricción de distancia máxima por vehículo. Es decir dados $v_a$, $v_b$ vehiculos y sus respectivas rutas $r_a$, $r_b$, se puede realizar un swap entre sus rutas si existe un cliente $c_{a_i}$ en la ruta de $r_a$ y otro cliente $c_{b_j}$ en $r_b$ tal que agregando $c_{a_i}$ en alguna posición de $r_b$ y agregando $c_{b_j}$ en alguna posición de $r_a$ cumpliendo:

\begin{equation*}
r_a.Dist + r_b.Dist < r_a'.Dist + r_b'.Dist \nonumber
\end{equation*}

\begin{equation*}
r_a'.Dist \leq v'_a.dMax
\end{equation*}

\begin{equation*}
r_b'.Dist \leq v'_b.dMax
\end{equation*}

Al aplicar esta heuristica a una solución, para todos par de rutas se ejecuta el $SwapDestinationsBetween$. Si hay $n$ rutas, la cantidad de pares de rutas es $n * (n-1) / 2$. $SwapDestinationsBetween$ prueba cada cliente de la ruta $a$ con cada cliente de la ruta $B$, si efectivamente conviene hacer un swap, lo realiza y continua probando pares de clientes. De modo de no estar cambiando multiples veces un mismo cliente entre dos rutas en una misma ejecución de $SwapDestinationsBetween$, cuando se cambia de ruta a un cliente, se lo banea de cambios hasta que no termine la actual ejecución de $SwapDestinationsBetween$. La metaheuristica Swap no mejora el beneficio total de una solución. Lo que hace es disminuir la distancia recorrida de alguna ruta, lo que aumente la posibilidad de encontrar algun cliente que agregar a las rutas respetando la restricción de la distancia máxima.

\bigskip

Su orden de complejidad es $0((n * (n-1) / 2 ) * clientes/n * clientes/n) ~ O(clientes^2/2)$

\subsection{Insert}

El objetivo de esta heuristica es encontrar una posición en alguna ruta para un cliente no visitado, respetando la restricción de distancia máxima. Básicamente para cada vehiculo y cada cliente no visitado se busca en que posición se puede insertar minimizando el incremento de distancia. Luego si la distancia resultante es menor a la distancia máxima del vehiculo, se inserta el cliente en tal posicion.

\bigskip

Este algoritmo tiene un $0(vehiculos * clientesNoVisitados * mediaClientesEnRuta)$

\bigskip

Claramente el mejor momento de ejecutar el insert es luego de a heuristica de swap ya que el swap disminuye la distancia de la sumatoria de los recorridos.

\subsection{2-opt (Swap dentro de una misma ruta)}

La idea de la heuristica 2-opt es buscar una orden alternativo de los clientes visitados en una misma ruta, de modo que disminuya la distancia recorrida de la ruta. Es decir un swap de posiciones de dos clientes dentro de una misma ruta.

\bigskip

Este algoritmo tiene un order de complejidad $0(vehiculos * mediaClientesEnRuta  * (mediaClientesEnRuta - 1) / 2) ~ 0 (vehiculos * mediaClientesEnRuta^2 / 2)$.

\bigskip

Del mismo modo que el swap, el 2-opt no incrementa el beneficio total de la solucion. En post de encontrar mejores resultados, es mejor ejecutar el 2-opt previo al insert.

\subsection{Replace}

Esta heuristica busca intercambiar un cliente no visitado por uno visitado de una ruta de modo que aumente el beneficio de la ruta y, como siempre, respetando la restricción de distancia máxima.

\bigskip

Replace tiene una complejidad de $0(vehiculos * clientesNoVisitados * mediaClientesEnRuta)$. Ya que esta heuristica es como un Insert pero con la penalidad de tener que remover un cliente, luego mejor ejecutarlo luego del insert.

\subsection{Reversibilidad del Decoder}

Agregar heuristicas de busqueda local entre generación de poblaciones conlleva un problema que debe resolverse. Al mejorar la solución, se modifican sus rutas. Ahora bien, si no se modifica su genetica, sus descendientes heredaran los genes que generan una solucion no optimizada por las busquedas locales. Del mismo modo que un hijo no hereda las cirujias esteticas de sus padres. 

\begin{equation*}
AplicarHeuristicasLocales(solucion) \neq Decoder(solucion.VectorAleatorioDeEnteros)
\end{equation*}

Para solucionar esto se debe modificar el vector aleatorio de enteros de la solucion mejorada de modo que al decodificar su vector aleatorio de enteros, genere la solucion mejorada.
