
\chapter{BRKGA algorithm for the TOP}

\section{Decodificador}

\subsection{Orden de los clientes a considerar}

En TOP un cliente es representado por unas coordenadas y un beneficio mayor a cero. Dado una instacia de un problema con $n$ clientes y un vector de enteros aleatorio de tamaño $n$, un decoder genera una solucion valida de un problema. Cada cliente tiene asociado un $id = 1,...,n$. Luego el vector de enteros aleatorios en realidad es un vector de tuplas de un $cliente.Id$ y un entero aleatorio. Al ordenar el vector de enteros aleatorio por su entero aleatorio, se ordenan los $cliente.Id$ del modo en que los vamos a utilizar.

TODO Pseudocodigo funcion de orden de los clientes

\subsection{Decodificador simple}

El decodificador simple recibe como parametro el vector de enteros aleatorios y con eso genera los clientes ordenados. Luego por cada vehiculo, si el siguiente cliente se puede incluir en la ruta se incluye sino considera que la ruta esta completa y pasa al siguiente vehiculo. Un cliente $c_i$ se puede agregar a la ruta si al agregarlo no supera la distancia maxima permitida para la ruta. Sean $v$ vehiculo, $dMax$ la distancia maxima de $v$, $dAct$ la distancia actual de $v$, $f$ el destino final de la ruta, $c_u$ el ultimo cliente agregado a la ruta de $v$ y $c_i$ cliente a evaluar agregar a la ruta de $v$. Luego:

\( dAct\, +\, distancia(c_u, c_i)\, +\, distancia(c_i, f)\, -\, distancia(c_u, f) \leq dMax\)

\bigskip

TODO Pseudocodigo deco simple generano rutas

\subsection{Caracteristicas y debilidades del decodificador simple}

Tiene un orden de complejidad de $O(\#clientes)$.

\bigskip

Sea $v$ el vector de clientes ordenados por un vector aleatorio de enteros. Existen $m$ indices $i_0 = 0, i_1, i_2, .., i_m$ donde $m$ es la cantidad de vehiculos y $0 \leq i_j \leq \#clientes$ tales que el vehiculo $j$ incluye en su recorrido a todos los clientes del subvector $v[i_{j-1}, i_j-1]$. Luego todos los clientes en el subvector $v[i_m, v.Length - 1]$ son clientes no alcanzados por la solucion.

\bigskip

Un problema que tiene este decodificar es en la existencia de un cliente inalcansable, es decir si existe $c$ cliente tal que:

\( distancia(i, c)\, +\, distancia(c, f)\, >\, dMax\)

Esto puede generar soluciones de la poblacion donde existan vehiculos con rutas vacias. La solucion facil a este problema es filtrando todos los clientes inalcansables previo a la ejecucion del BRKGA.

\bigskip

Otro problema que tiene este decodificador es que cambia de vehiculo al primer intento fallido de expandir su ruta. Luego puede generar soluciones con rutas muy pequeñas, por este motivo implemente un Decodificador Goloso.

\bigskip

TODO Resultados del deco simple?

\subsection{Decodificador Goloso}

El decodificador goloso en principio funciona igual que el decodificador simple hasta que llega a un cliente que no pudo agregar a la ruta de un vehiculo. En este caso, en vez de pasar a trabajar con el siguiente vehiculo disponible, intenta agregar al siguiente cliente y asi sucesivamente hasta que no hay mas clientes que intentar. Luego pasa al siguiene vehiculo intentando solamente con los clientes no asignadas a otra ruta y siempre respetando el orden de los clientes asignado por el vector de enteros aleatorios.

\bigskip

TODO Pseudocodigo deco goloso generano rutas

\bigskip

Con esta modificacion su orden complejidad aumenta a $0(\#clientes * \#vehiculos)$. De todos modos la cantidad de vehiculos en todas las intancias del becnhmark utilizado siempre son menores o iguales a 4, luego no tiene un impacto en su performance. En promedio aumenta el profit de las soluciones generadas por el decodificador.

\bigskip

TODO Resultados del deco goloso?

\subsection{Decodificador reversible}

TODO Explicar el algoritmo inverso

\section{BRKGA}

\subsection{Macro}

En una primera intancia se implementa un BRKGA estandar. Dado una instancia de un problema, primero se genera la poblacion inicial. Luego mientras no se cumpla la condicion de parada, evolucionamos la poblacion. Es decir generamos una nueva generacion de soluciones a partir de la generacion anterior como se explico en capitulo 6 BRKGA.

\begin{lstlisting}
public Solution RunBRKGA(ProblemManager problemManager)
{
    ProblemManager.InitializePopulation();

    while (!ProblemManager.StoppingRuleFulfilled())
        ProblemManager.EvolvePopulation();

    return ProblemManager.Population.GetMostProfitableSolution();
}
\end{lstlisting}


\subsection{Configuracion}

A modo de poder testear distintas configuraciones del BRKGA, se creo un objeto $Configuration$ que setea todas las configuraciones que impactan en el resultado final del BRKGA. Tales como variables utilizadas en la condicion de parada, tamaño de la poblacion, porcentaje de la poblacion elite, heuristicas de busqueda local, etc.

\subsection{Inicializacion de la Poblacion}

Existe una propiedad en el objeto $Configuration$ llamado $PopulationSize$, es un entero que se utiliza para setear el tamaña de la poblacion. Luego para generar la poblacion inicial se genereran $PopulationSize$ vectores de enteros aleatorios de tamaño $\#clientes$ de la instancia del problema. Este conjunto de vectores se lo pasa como argumento al decodificaor, quien genere un individuo por cada vector de enteros aleatorios.

\subsection{Condicion de parada}

En un principio la condicion de parada era simple, el bucle terminaba cuando iteraba una $x$ cantidad de veces representado en el objeto $Configurations$ como $MinIerations$. Es decir que el bucle principal cortaba luego de evolucionar la poblacion $MinIerations$ veces. Posteriormente se agrego una condicion de corte adicional, para cortar la función objetivo de la mejor solucion durante las ultimas $n$ generaciones no debia cambiar. Es decir durante las ultimas $n$ genereciones no aparecio una nueva mejor solucion. Este valor es ajustable desde la propiedad $MinNoChanges$ del objeto $Configurations$.

\begin{lstlisting}
public bool StoppingRuleFulfilled()
{ 
    return PopulationGenerator.Generation >= MinIterations && NoChanges();
}
\end{lstlisting}

\subsection{Evolucion de la poblacion}

Se toma la población y se los ordena descendente por la función objetivo. Se setea la población de elite y la non-elite. La población de elite son los mejores $x$ individuos de la poblacion. Siendo $x$ un porcentaje de la poblacion total seteado con la propiedad $ElitePercentage$ del objeto $Configuration$. La poblacion non-elite son todos aquellos individuos no incluidos en la poblacion de elite. Luego se genera $y$ individuos mutantes, $y$ es un porcentaje de la poblacion total seteado por la propiedad $MutantPercentage$ del objeto $Configuration$. Pasan a la nueva generecion todos los individuos de la poblacion de elite y se agregan los de la poblacion mutante. Finalmente se completa la nueva generación emparentando individuos de la población de elite con individuos de la población non-elite. Los padres son elegidos al azar y el proceso de apareamiento se realiza como se describe en el capítulo BRKGA. Como la probabilidad de generar soluciones identicas es alta, a modo de no repetir soluciones, antes de insertar el individuo resultante se verifica que no exista otra solucion identica en la nueva generación.

\begin{lstlisting}
public Population Evolve(Population population)
{
    population.EncodedProblems = population.GetOrderByMostProfitable();

    var elitePopulation = population.EncodedProblems.Take(EliteSize).ToList();
    var nonElitePopulation = population.EncodedProblems.Skip(EliteSize).Take(NonEliteSize).ToList();
    var mutatants = Generate(MutatansSize).EncodedProblems;

    var evolvedPopulation = new Population(elitePopulation, mutatants);

    while (evolvedPopulation.CurrentPopulationSize() < PopulationSize)
    {
        var childSolution = Mate(GetRandomItem(elitePopulation), GetRandomItem(nonElitePopulation));
        if (evolvedPopulation.EncodedProblems.Any(x => x.IsEquivalenteTo(childSolution)))
            evolvedPopulation.EncodedProblems.Add(GenerateEncodedSolution(evolvedPopulation.EncodedProblems));
        else
            evolvedPopulation.EncodedProblems.Add(childSolution);
    }
    return evolvedPopulation;
}
\end{lstlisting}

Verificar que dos soluciones son iguales tiene un costo mu bajo en BRKGA. Esto se debe a que el decodificador es un algoritmo deterministico. Por lo tanto para dos vectores de enteros aleatorios cuyo orden de clientes que genere sea el mismo, el decodificador generara la misma solucion. Luego lo unico que hay que comparar es el hash de ambas soluciones y esto se puede hacer en $O(1)$. El hash de una solución, se calcula una sola vez cuando se construye la solución a partir de su vector de enteros aleatorios. El hash es una concatenación del orden resultante de los $cliente.Id$ itercalados con un separador. Si ya existe un individuo con el mismo hash, se genera una solución mutante y continua el apareamiento de otros dos individuos.

\bigskip

En una primera instancia se insertaban los individuos sin realizar esta verificación. Luego ocurria un efecto bola de nieve donde cada nueva generación tenia cada vez mas individuos repetidos. Esto reducía ampliamente la cantidad de soluciones diferentes exploradas, luego reducía fuertemente la frecuencia con la que una nueva mejor solución se generaba. Además si uno tiene varios individuos iguales en una solución, el algoritmo se vuelve menos eficiente ya que repite trabajo en donde obtiene los mismos resultados. Entonces el costo total de validar unicidad en la insercion $O(PopulationSize * NonElitePopulationSize)$ resulta muy bajo comparado con el costo de trabajar con multiples soluciones repetidas.

\begin{lstlisting}
private string GetHash()
{
    if (string.IsNullOrEmpty(hash))
        hash = string.Join("@", GetOrderedRandomKeys().Select(k => k.PositionIndex.ToString()));

    return hash;
}
\end{lstlisting}

\subsection{Resultados de la primer version}

La primer version del BRKGA para TOP no incluía el objeto de configuración y permitóa insertar soluciones repetidas en una misma generación. Para instancias de testeo pequeñas esta version funcionaba tan bien como Chao, Golden y Wasil (CGW), Tang y Miller-Hooks (TMH) y Archetti, Hertz, Speranza (AHS). Desarfotunadamente no sucedia lo mismo cuando aumentaban la cantidad de clientes y vehículos. El beneficio de la mejor solución encontrada no llegaba al 50% del benefio de los algoritmos de CGW, TMH y AHS en instancias grandes.

\bigskip

Con el fin de mejorar los resultados cree el objeto Configuracion y fui variando los valores de $MinIerations$, $MinNoChanges$, $PopulationSize$, $ElitePercentage$, $MutantPercentage$ y $EliteGenChance$. Tome una instancia de testeo grande como referencia para comparar resultados y fui modificando estas variables observando cuando mejoraba. Logre mejorar un poco los resultados, aun asi todavía estaban lejos del objetivo.

\subsection{Heuristicas de busqueda local}

Con el fin de mejorar los resultados se implementaron heuristicas de busqueda local. La idea era aplicar estas heuristicas a la mejor solución de cada nueva generación. En caso de que a la mejor solución ya se le habia aplicado las heuristicas, se aplican a la siguiente mejor solución. Esto puede suceder ya que las mejores soluciones pertenecen al conjunto de elite.

\subsection{Swap (Entre rutas distintas)}

El objetivo de esta heuristica es encontrar e intercambiar clientes entre dos rutas distintas con el fin de disminuir la suma de las distancias recorridas de ambas rutas mientras sigan respetando la restricción de distancia máxima por vehículo. Es decir dados $v_a$, $v_b$ vehiculos y sus respectivas rutas $r_a$, $r_b$, se puede realizar un swap entre sus rutas si existe un cliente $c_{a_i}$ en la ruta de $r_a$ y otro cliente $c_{b_j}$ en $r_b$ tal que agregando $c_{a_i}$ en alguna posición de $r_b$ y agregando $c_{b_j}$ en alguna posición de $r_a$ cumpliendo:

\begin{equation*}
r_a.Dist + r_b.Dist < r_a'.Dist + r_b'.Dist \nonumber
\end{equation*}

\begin{equation*}
r_a'.Dist \leq v'_a.dMax
\end{equation*}

\begin{equation*}
r_b'.Dist \leq v'_b.dMax
\end{equation*}

Al aplicar esta heuristica a una solución, para todos par de rutas se ejecuta el $SwapDestinationsBetween$. Si hay $n$ rutas, la cantidad de pares de rutas es $n * (n-1) / 2$. $SwapDestinationsBetween$ prueba cada cliente de la ruta $a$ con cada cliente de la ruta $B$, si efectivamente conviene hacer un swap, lo realiza y continua probando pares de clientes. De modo de no estar cambiando multiples veces un mismo cliente entre dos rutas en una misma ejecución de $SwapDestinationsBetween$, cuando se cambia de ruta a un cliente, se lo banea de cambios hasta que no termine la actual ejecución de $SwapDestinationsBetween$. La metaheuristica Swap no mejora el beneficio total de una solución. Lo que hace es disminuir la distancia recorrida de alguna ruta, lo que aumente la posibilidad de encontrar algun cliente que agregar a las rutas respetando la restricción de la distancia máxima.

\bigskip

Su orden de complejidad es $0((n * (n-1) / 2 ) * clientes/n * clientes/n) ~ O(clientes^2/2)$

\subsection{Insert}

El objetivo de esta heuristica es encontrar una posición en alguna ruta para un cliente no visitado, respetando la restricción de distancia máxima. Básicamente para cada vehiculo y cada cliente no visitado se busca en que posición se puede insertar minimizando el incremento de distancia. Luego si la distancia resultante es menor a la distancia máxima del vehiculo, se inserta el cliente en tal posicion.

\bigskip

Este algoritmo tiene un $0(vehiculos * clientesNoVisitados * mediaClientesEnRuta)$

\bigskip

Claramente el mejor momento de ejecutar el insert es luego de a heuristica de swap ya que el swap disminuye la distancia de la sumatoria de los recorridos.

\subsection{2-opt (Swap dentro de una misma ruta)}

La idea de la heuristica 2-opt es buscar una orden alternativo de los clientes visitados en una misma ruta, de modo que disminuya la distancia recorrida de la ruta. Es decir un swap de posiciones de dos clientes dentro de una misma ruta.

\bigskip

Este algoritmo tiene un order de complejidad $0(vehiculos * mediaClientesEnRuta  * (mediaClientesEnRuta - 1) / 2) ~ 0 (vehiculos * mediaClientesEnRuta^2 / 2)$.

\bigskip

Del mismo modo que el swap, el 2-opt no incrementa el beneficio total de la solucion. En post de encontrar mejores resultados, es mejor ejecutar el 2-opt previo al insert.

\subsection{Replace}

Esta heuristica busca intercambiar un cliente no visitado por uno visitado de una ruta de modo que aumente el beneficio de la ruta y, como siempre, respetando la restricción de distancia máxima.

\bigskip

Replace tiene una complejidad de $0(vehiculos * clientesNoVisitados * mediaClientesEnRuta)$. Ya que esta heuristica es como un Insert pero con la penalidad de tener que remover un cliente, luego mejor ejecutarlo luego del insert.

\subsection{Reversibilidad del Decoder}

Agregar heuristicas de busqueda local entre generación de poblaciones conlleva un problema que debe resolverse. Al mejorar la solución, se modifican sus rutas. Ahora bien, si no se modifica su genetica, sus descendientes heredaran los genes que generan una solucion no optimizada por las busquedas locales. Del mismo modo que un hijo no hereda las cirujias esteticas de sus padres. 

\begin{equation*}
AplicarHeuristicasLocales(solucion) \neq Decoder(solucion.VectorAleatorioDeEnteros)
\end{equation*}

Para solucionar esto se debe modificar el vector aleatorio de enteros de la solucion mejorada de modo que al decodificar su vector aleatorio de enteros, genere la solucion mejorada.
