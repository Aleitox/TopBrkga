
\chapter{Desarrollo del algoritmo BRKGA con búsqueda local para el TOP}

En el presente capítulo describiré en detalle la solución que implementé para el \textit{Team Orienteering Problem}. La implementación se la puede dividir en 3 módulos importantes. Primero el decodificador, que como mencioné en el capítulo BRKGA tiene la tarea de convertir un vector de números reales aleatorios en una solución válida del problema. El siguiente módulo sería el algoritmo BRKGA, cuya implementación podría hacerse con total independencia del problema a resolver. Por último las búsquedas locales aplicadas en cada nueva generación a los mejores individuos de la población. 

\bigskip

En este capítulo mostré los resultados parciales obtenidos a lo largo del desarrollo de mi implementación. A modo de analizar el rendimiento de una solución de forma simple y rápida creé un índice que llamo \textit{índice de efectividad} ($i_e$). El $i_e$ muestra que tan buena es la solución encontrada. Esto se hace comparando el beneficio de mi solución encontrada con el beneficio de la mejor solución previamente publicada para la misma instancia del problema. Se utilizaron los resultados de los trabajos previos mencionados para crear el $i_e$. Es importante destacar que el $i_e$ no es la función objetivo. La función objetivo es maximizar el beneficio a recolectar. 

\bigskip

Se seleccionó un subconjunto del benchmark de instancias de problemas de Chao y Tsiligirides \cite{IntancesChaoTsiligirides} para medir el progreso de mi desarrollo. Las seis instancias seleccionadas varían en cantidad de clientes y vehículos, esto es importante para que el análisis del rendimiento sea lo más objetivo posible. Luego de obtener una solución para cada una de estas instancias, se calcula el $i_e$ que definí de la siguiente manera:

\begin{equation}
i_e(brkga_{v.x},ins_n) = benefit(brkga_{v.x}(ins_n)) / bestBenefitFor(ins_n) \label{eq:iefectividad}
\end{equation}

\bigskip

En la función \eqref{eq:iefectividad} $brkga_{v.x}$ representa la versión $x$ de mi $brkga$, $ins_n$ representa la n-ésima instancia del benchmark de problemas y $bestBenefitFor(ins_n)$ representa el mejor beneficio obtenido para la misma instancia en los trabajos previamente publicados. Analizar el rendimiento de mi implementación utilizando el $i_e$ es muy sencillo. Si $i_e = 1$ para $ins_n$, entonces la solución encontrada es tan buena como la mejor solución encontrada hasta el momento, lo que significa que mi implementación es óptima para la instancia $ins_n$. Cuanto más cercano a 1 es $i_e$, más competitiva es mi implentación frente a los trabajos previos. Lamentablemente no existe instancia en el benchmark de problemas tal que mi implementación haya obtenido un resultado mayor al mejor beneficio obtenido para la misma instancia en algún trabajo previo, por lo tanto $i_e \leq 1$.

\bigskip

Se explicará en detalle el funcionamiento de los módulos que componen la implementación, incluyendo su pseudocódigo y los resultados parciales obtenidos luego de implementar tal módulo. El pseudocódigo utilizado sigue la sintaxis de c\#, el lenguaje en el cual implementé el desarrollo. El objetivo del pseudocódigo es facilitar el entendimiento del funcionamiento de los algoritmos que describiré.


\bigskip

Para la valuación de $i_e$ elegí seis instancias del benchmark bien diversas entre sí. Tomé dos pequeñas, dos medianas y dos grandes, cuyas descripciones pueden observarse en la tabla \ref{tab:instanciasDiversas}. Como mencioné en el abstract, el benchmark de instancias se compone de siete conjuntos. Dentro de cada set, todas las instancias contienen los mismo clientes. Esto significa que tiene las mismas coordenadas en el eje cartesiano y el mismo beneficio. Dentro de un set las instancias se diferencian entre si por la cantidad de vehículos que poseen y el $d_{max}$ de sus rutas. Esto es importante mencionarlo ya que ayuda a entender los resultados parciales que obtuve sobre las seis instancias seleccionadas. Los nombres de las instancias nos dan información sobre el conjunto del benchmarck al cual pertenecen y la cantidad de vehículos que tienen. Por ejemplo la instancia \textit{p2.3.g} tiene pertenece al conjunto número 2 del benchmark y tiene 3 vehículos. La instancia \textit{p2.2.k} también pertenece al conjunto número 2 del benchmark, lo que significa que tiene los mismos clientes que \textit{p2.3.g}.

\begin{table}
\begin{center}
\begin{tabular}
{ |c|c|c|c|c| } 
\hline
Autor & Instancia & Nodos & Vehículos & $d_{max}$ \\
\hline
Tsiligirides & p2.2.k & 21 & 2 & 22.50 \\
Tsiligirides & p2.3.g & 21 & 3 & 10.70 \\
Tsiligirides & p3.4.p & 33 & 4 & 22.50 \\
Chao & p5.3.x & 66 & 3 & 40.00 \\
Chao & p7.2.e & 102 & 2 & 50.00 \\
Chao & p7.4.t & 102 & 4 & 100.00 \\
\hline
\end{tabular}
\end{center}
\caption{Instancias seleccionadas para el monitoreo del progreso del desarrollo.}
\label{tab:instanciasDiversas}
\end{table}


\bigskip

Las tablas donde mostraré el $i_e$ y el beneficio de los resultados parciales tendrá un subconjunto de los siguientes encabezados:

\begin{center}
\begin{tabular}{ |c|c|c|c|c|c|c|c|c|c|c|c|c| } 
 \hline
Instancia & N/V/D & Config & $T_{avg}$ & $B_{max}$ & $B_{min}$ & $B_{avg}$ & $i_{eMax}$ & $i_{eAvg}$ & Best \\
\hline
\end{tabular}
\end{center}

\bigskip

Descripciones:
\begin{itemize}
	\item \textbf{$Instancia$}: Nombre de la instancia utilizada.
	\item \textbf{$N/V/D$}: Cantidad de \textbf{N}odos / Cantidad de \textbf{V}ehículos / \textbf{D}istancia máxima de la ruta del vehículo.
	\item \textbf{$Config$}: La configuración utilizada de mi BRKGA al ejecutar la prueba. Es un código que sintetiza la configuración global del algoritmo, explicado en detalle más adelante (ver sección \ref{sec:config}).
	\item \textbf{$T_{avg}$}: El \textbf{T}iempo promedio en milisegundos de la ejecución del algoritmo para la instancia mencionada.
	\item \textbf{$B_{max}$}: El \textbf{B}eneficio máximo que obtuve para la instancia mencionada.
	\item \textbf{$B_{min}$}: El \textbf{B}eneficio mínimo que obtuve para la instancia mencionada.
	\item \textbf{$B_{avg}$}: El \textbf{B}eneficio promedio que obtuve para la instancia mencionada.
	\item \textbf{$i_{eMax}$}: Indice de efectividad máximo. Utiliza mi beneficio máximo obtenido para la instancia mencionada.
	\item \textbf{$i_{eAvg}$}: Indice de efectividad promedio. Utiliza mi beneficio promedio obtenido para la instancia mencionada.
	\item \textbf{$Best$}: Máximo beneficio obtenido por alguna trabajo previo sobre la misma instancia mencionada.
\end{itemize}

\section{Decodificador}

El decodificador debe generar una solución válida del problema dado un vector de claves aleatorios y conociendo la instancia del problema (vehículos disponibles, clientes, $d_{max}$, etc). Con tal objetivo construye una solución asignando clientes a las rutas de los vehículos disponibles respetando $d_{max}$. De acá en adelante llamaré clientes a todos los nodos que tienen un beneficio mayor a cero. Es decir, todos los nodos excepto el nodo de inicio y fin de recorrido. El orden en que toma los clientes a asignar es clave y determina la solución resultante. Tal orden es determinado por el el vector de claves aleatorias. Por lo tanto el vector tendrá una longitud equivalente a la cantidad de clientes del problema.

\bigskip

Propuse dos decodificadores, uno al cual llamé \textit{Decodificador Simple} y al otro lo llamé \textit{Decodificador Goloso}. Ambos decodificadores tienen sus ventajas y desventajas.

\subsection{Orden en que los clientes se intentan agregar a las rutas.}\label{sec:ordenDeco}

Como dije, dado una instancia de un problema con $n$ clientes y un vector de claves aleatorias del mismo tamaño $n$, un decodificador genera una solución valida de un problema. En mi implementación, modelé una clave aleatoria con el objeto \textit{RandomKey}. Un \textit{RandomKey} tiene dos propiedades, un entero aleatorio llamado \textit{Key} y otro entero llamado \textit{ClientId} que siempre toma el valor de un identificador de uno de los clientes de la instancia. Podemos ver el objeto \textit{RandomKey} en el pseudocódigo \ref{func:RandomKey}.

\bigskip

\begin{lstlisting} [caption={Objeto \textit{RandomKey}.},label={func:RandomKey}]
public class RandomKey
{        
	public int Key { get; private set; }
	public int ClientId { get; private set; }
}
\end{lstlisting}

\bigskip

El propósito de $ClientId$ es asociar un \textit{RandomKey} con un cliente. Existe un vector de clientes en el Mapa del problema, a cada cliente se le asigna un identificador que es un numero entero en el intervalo $[1, \#clientes]$. Luego para un vector de \textit{RandomKeys} de tamaño $\#clientes$ no existen dos \textit{RandomKeys} con mismo valor de \textit{ClientId} y todos los \textit{ClientId} se encuentran en el intervalo $[1, \#clientes]$. De esta forma cada \textit{RandomKey} siempre se asocia con un solo cliente. Luego de asociar cada cliente con su correspondiente \textit{RandomKey}, se los ordena de forma ascendente por el \textit{Key} del \textit{RandomKey} con el cual se asoció. Este es el orden por el cual se tomaran los clientes para ser asignados a los vehículos. El pseudocódigo \ref{func:GetOrderedClients} muestra como se obtienen los clientes ordenados dado un vector de \textit{RandomKeys}. En el figura \ref{fig:RandomKeysOrdenando} se puede observar un vector de \textit{RandomKeys} en su estado inicial y luego ordenado por su campo \textit{Key} mostrando el orden en que se tomarán los clientes.

\bigskip

\begin{minipage}{\linewidth}
\begin{lstlisting} [caption={Dada una lista de \textit{RandomKeys}, se obtienen los clientes ordenados.},label={func:GetOrderedClients}]
public List<Client> GetOrderedClients(List<RandomKey> randomKeys)
{        
	var orderedKeys = randomKeys.OrderBy(r => r.Key)
	return orderedKeys.Select(r => Map.Clients[r.ClientId]);
}
\end{lstlisting}
\end{minipage}

\begin{figure}[h]
	\caption{Ejemplo de como el vector de \textit{RandomKeys} determina el orden de los clientes.}
	\centering
	\includegraphics[width=14cm]{RandomKeysOrdenando}
	\label{fig:RandomKeysOrdenando}
\end{figure}

\subsection{Decodificador Simple}

El decodificador simple recibe como parámetro el vector de \textit{RandomKeys} y lo primero que hace es obtener los clientes ordenados como describimos anteriormente. Luego por cada vehículo, si el siguiente cliente se puede incluir en la ruta se incluye sino considera que la ruta esta completa y pasa al siguiente vehículo. Estos se puede ver en detalle en el pseudocódigo \ref{func:decodeSimple}. 

\bigskip

\begin{minipage}{\linewidth}
\begin{lstlisting} [caption={Función \textit{Decode} del decodificador simple.}, label={func:decodeSimple}]
public Solution Decode(List<RandomKey> randomKeys, ProblemInfo pi)
{
	var clients = GetOrderedClients(randomKeys);
	var vehicles = pi.GetVehicles();	
	var iv = 0;
	var ic = 0;	
	do
	{
		if(vehicles[iv].CanVisit(clients[ic]))
		{
			vehicles[iv].AddClient(clients[ic]);
			ic++;
		}
		else
		{
			iv++;			
		}
		
	} while(iv < vehicles.Length && ic < clients.Length)	
	var solution = pi.InstanceSolution(vehicles);
	return problem;
}
\end{lstlisting}
\end{minipage}

Un cliente $c_i$ se puede agregar a la ruta si al agregarlo, la ruta no supera su distancia máxima permitida. Sean $v$ vehículo, $d_{max}$ la distancia máxima de $v$, $d_{act}$ la distancia actual de la ruta de $v$, $n_f$ el nodo final de la ruta, $c_u$ el último cliente agregado a la ruta de $v$ y $c_i$ cliente que se intenta agregar a la ruta de $v$. Si aún no se insertaron clientes en la ruta, $c_u = n_i$ donde $n_i$ representa el nodo inicial de la ruta. Como podemos observar en el pseudocódigo \ref{func:decodeSimple}, creé un método llamado \textit{CanVisit}, que modela la fórmula \ref{eq:canVisit}, que retorna \textit{true} cuando $c_i$ se puede agregar a la ruta y \textit{false} en caso contrario

\bigskip

\begin{mycapequ}[!ht]
	\caption{Formula matemática que modela el método \textit{CanVisit}.}
	\begin{equation} \label{eq:canVisit}
	d_{act}\, +\, distancia(c_u, c_i)\, +\, distancia(c_i, n_f)\, -\, distancia(c_u, n_f) \leq d_{max}
	\end{equation}
\end{mycapequ}

\bigskip

Una vez que terminé de implementar el decodificador simple, analicé el rendimiento de las soluciones generadas a partir de este decodificador. Hice este análisis para saber que tan buena sería la población inicial de mi algoritmo BRKGA cuando se utiliza el decodificador simple. Para realizar este análisis creé 200 vectores de $RandomKeys$ que el decodificador simple convirtió en 200 soluciones válidas del problema. Sobre estas 200 soluciones calculé el beneficio máximo, promedio y mínimo, y sus índices de efectividad promedio y máximo. Esto se realizó para cada una de las seis instancias del benchmark seleccionadas anteriormente \ref{tab:instanciasDiversas}. Podemos observar los resultados en la tabla \ref{tab:resultadosDecoSimple}.

\bigskip

\begin{table}
\begin{center}
\begin{tabular}{ |c|c|c|c|c|c|c|c| } 
\hline
Instancia & N/V/D & $B_{min}$ & $B_{avg}$ & $B_{max}$ & $i_{eAvg}$ & $i_{eMax}$ & $Best$ \\
\hline
p2.2.k & 21/2/22.50 & 40 & 102 & 175 & 0.37 & 0.64 & 275 \\
p2.3.g & 21/3/10.70 & 45 & 83 & 140 & 0.57 & 0.97 & 145 \\
p3.4.p & 33/4/22.50 & 90 & 170 & 270 & 0.30 & 0.48 & 560 \\
p5.3.x & 66/3/40.00 & 195 & 295 & 405 & 0.19 & 0.26 & 1555 \\
p7.2.e & 102/2/50.00 & 8 & 39 & 98 & 0.13 & 0.34 & 290 \\
p7.4.t & 102/4/100.00 & 40 & 116 & 221 & 0.11 & 0.21 & 1077 \\
\hline
\end{tabular}
\end{center}
\caption{Resultados de las 200 soluciones generadas por el decodificar simple.}
\label{tab:resultadosDecoSimple}
\end{table}

En los resultados de la tabla \ref{tab:resultadosDecoSimple} vemos que para instancias pequeñas los resultados son mejores. En la instancia \textit{p2.3.g} una de las 200 soluciones quedo muy cercana a la mejor solucion conocida, obteniendo un $i_{eMax}=0.97$. Esta instancia tiene los mismos clientes que la instancia \textit{p2.2.k} pero como el $d_{max}$ de \textit{p2.3.g} es prácticamente la mitad que el de \textit{p2.2.k} luego la cantidad de combinaciones de rutas diferentes disminuye considerablemente. Es por eso que obtuve mejores resultados de \textit{p2.3.g}. Por otro lado podemos observar $i_{eAvg}$ disminuye a medida que la instancia tiene mayor numero de clientes. Los peores resultados los obtuvo la instancia \textit{p7.4.t}, la instancia de mayor cantidad de clientes y mayor $d_{max}$.

\subsection{Características y debilidades del decodificador simple}

Este decodificador es simple y rápido, su orden de complejidad es de $O(\#clientes + \#vehiculos)$. En la práctica nunca se llega a visitar a todos los clientes ya que cambia de vehículo en cuanto encontró un cliente que no logro insertar en su ruta. Por lo tanto en la practica nunca llega al orden de complejidad mencionado. Esto es una gran ventaja ya que en cada iteración del BRKGA se va a decodificar una cantidad $\#Poblacion$ de veces. Luego una decodificación rápida nos permitirá mayor cantidad de generaciones.

\bigskip

Una característica menos relevante es el orden en que quedan los clientes asignados en los vehículos al ver el vector de \textit{RandomKeys}.  Sea $v$ el vector de clientes ordenados por un vector de \textit{RandomKeys}. Existen $m+1$ índices $i_0 = 0, i_1, i_2, .., i_m$ donde $m$ es la cantidad de vehículos y $0 \leq i_j \leq \#clientes$ tales que el vehículo $j$ incluye en su recorrido a todos los clientes del subvector $v[i_{j-1}, i_j-1]$. Luego todos los clientes en el subvector $v[i_m, v.Length - 1]$ son clientes no alcanzados por la solución. En otras palabras, los clientes quedan agrupados por vehículo cuando los vemos en el vector ordenado. Esto puede verse en la figura \ref{fig:DistribucionClientesDecoSimple}.

\begin{figure}[h]
	\caption{Posible distribución de clientes utilizando el decodificador simple para el vector de \textit{RandomKeys} de ejemplo. La primer ruta visita primero al cliente 6 y luego al 2. Como no pudo incluir al cliente 5, se cerró la ruta del primer vehículo y siguió con el próximo vehículo disponible. La segunda ruta visita al cliente 5 y luego al cliente 1. Como no pudo visitar al cliente 4 por la limitación de tiempo, no intento agregar a los siguientes clientes.}
	\centering
	\includegraphics[width=14cm]{DistribucionClientesDecoSimple}
	\label{fig:DistribucionClientesDecoSimple}
\end{figure}

\bigskip

Un problema que tiene este decodificar es en la existencia de un cliente inalcanzable. Un cliente inalcanzable es aquel que no puede insertarse en una ruta aún cuando la ruta no contiene ningún otro cliente. En la función \ref{eq:inalcanzable} podemos distinguir cuando un cliente no se lo puede agregar en ninguna ruta.

\bigskip

\begin{mycapequ}[!ht]
	\caption{Función para evaluar si un cliente es inalcanzable.}
	\begin{equation} \label{eq:inalcanzable}
	distancia(n_i, c)\, +\, distancia(c, n_f)\, >\, d_{max}
	\end{equation}
\end{mycapequ}

\bigskip

Si utilizamos el decodificador simple y tenemos un cliente inalcanzable en el mapa, existe el escenario en el cual hay soluciones de la población donde todos los vehículos tienen sus rutas vacías. Supongamos que existe un cliente inalcanzable y que es el primer cliente que se intenta agregar en la ruta del primer vehículo. Como el cliente es inalcanzable no entra en la ruta, entonces se considera que el vehículo tiene la ruta completa y se pasa con el siguiente vehículo dejando su ruta vacía. Esto se repite con todos los vehículos ya que tienen el mismo valor de $d_{max}$. La solución óptima a este problema es filtrar todos los clientes inalcanzables previo a la ejecución del BRKGA utilizando un método que modele la función \ref{eq:inalcanzable}. Haciendo esto no solo evitamos el escenario de rutas vacías, también reducimos el tamaño del problema antes de comenzar a resolverlo. 

\bigskip

Como el decodificador simple cambia de vehículo al primer intento fallido de expandir su ruta, las soluciones que genera tienen rutas muy pequeñas. Seguramente existen algunos clientes que podrían insertarse a la ruta del vehículo actual. Es por este motivo implementé el \textit{Decodificador Goloso}.


\subsection{Decodificador Goloso}

El decodificador goloso en principio funciona igual que el decodificador simple hasta que llega a un cliente que no puede agregar a la ruta de un vehículo determinado. En este caso, en vez de pasar a trabajar con el siguiente vehículo disponible, intenta agregar al siguiente cliente y así sucesivamente hasta que no hay más clientes con los cuales intentar agregar al vehículo actual. Después, al pasar al siguiente vehículo intenta con los clientes no asignados a los vehículos anteriores y siempre respetando el orden de los clientes asignado por el vector de \textit{RandomKeys}. Podemos ver en detalle como implementé el método \textit{Decode} del decodificador goloso en el pseudocódigo \ref{func:decodeGoloso}.  

\bigskip

\begin{minipage}{\linewidth}
\begin{lstlisting} [caption={Función \textit{Decode} del decodificador goloso. }, label={func:decodeGoloso}]
public Solution Decode(List<RandomKey> randomKeys, ProblemInfo pi)
{
	var clients = GetOrderedClients(randomKeys);
	var cIterator = new Iterator(clients);
	var vehicles = pi.GetVehicles();	
	var iv = 0;
	while(iv < vehicles.Length)
	{
		var currentClient = cIterator.Next;
		while(currentClient != null)
		{
			if(vehicles[iv].CanVisit(currentClient))
			{
				vehicles[iv].AddClient(currentClient);
				cIterator.Remove(currentClient);
			}
			currentClient = cIterator.Next;
		}
		cIterator.ToStartingPosition;
	}
	var solution = pi.InstanceSolution(vehicles);
	return problem;
}
\end{lstlisting}
\end{minipage}

\bigskip

Como podemos observar en el pseudocódigo \ref{func:decodeGoloso}, su complejidad es $0(\#clientes * \#vehiculos)$. El método \textit{Decode} es usado tantas veces a lo largo del BRKGA que este pequeño aumento en su complejidad algorítmica tiene un impacto visible en el tiempo de ejecución total. Por otro lado, utilizar el decodificador goloso mejora el beneficio de las soluciones generadas respecto de las soluciones generadas por el decodificador simple. Esa es la compensación que tenemos entre el decodificador simple y el goloso.

\bigskip

Otra característica que podemos mencionar sobre el decodificador goloso es que al observar el vector ordenado de \textit{RandomKeys}, ya no tenemos a los clientes de forma continua según su vehículo asignado como sucedía con el decodificador simple. Esto puede verse en la figura \ref{fig:DistribucionClientesDecoGoloso}.

\begin{figure}[h]
	\caption{Posible distribución de clientes utilizando el decodificador goloso para el vector de RandomKeys de ejemplo. La primer ruta visita a los clientes 6, 2 y por último al 8. El decodificador goloso no cerró la ruta del primer vehículo al no poder incluir al cliente 5, en cambio intenta con el resto de los clientes aún no visitados manteniendo el orden y logra insertar al cliente 8. De un modo similar, sucede con la segunda ruta al no poder incluir al cliente 4. Con el cliente 8 no lo intenta por que esta asignado a la primer ruta. Intenta con éxito insertar al cliente 3 y por ultimo falla con el cliente 7. }
	\centering
	\includegraphics[width=14cm]{DistribucionClientesDecoGoloso}
	\label{fig:DistribucionClientesDecoGoloso}
\end{figure}

\bigskip

Le hice un análisis de rendimiento al decodificador goloso del mismo modo que lo hice con el decodificador simple. Generé otros 200 vectores de \textit{RandomKeys} para cada una de las mismas seis instancias de problemas y el decodificador goloso creó 200 soluciones válidas.

\begin{table}
\begin{center}
\begin{tabular}{ |c|c|c|c|c|c|c|c|c|c| } 
\hline
Instancia & N/V/D & $B_{min}$ & $B_{avg}$ & $B_{max}$ & $i_{eAvg}$ & $i_{eMax}$ & $Best$ \\
\hline
p2.2.k & 21/2/22.50 & 95 & 164 & 260 & 0.60 & 0.95 & 275 \\
p2.3.g & 21/3/10.70 & 95 & 122 & 140 & 0.84 & 0.97 & 145 \\
p3.4.p & 33/4/22.50 & 180 & 288 & 410 & 0.51 & 0.73 & 560 \\
p5.3.x & 66/3/40.00 & 305 & 412 & 525 & 0.26 & 0.34 & 1555 \\
p7.2.e & 102/2/50.00 & 31 & 96 & 163 & 0.33 & 0.56 & 290 \\
p7.4.t & 102/4/100.00 & 160 & 280 & 438 & 0.26 & 0.41 & 1077 \\
\hline
\end{tabular}
\end{center}
\caption{Resultados de las 200 soluciones generadas por el decodificar goloso.}
\label{tab:resultadosDecoGoloso}
\end{table}

\bigskip

Como podemos ver en la tabla \ref{tab:resultadosDecoGoloso}, todos los resultados promedio, mínimo y máximos mejoran considerablemente respecto de los resultados obtenidos con el decodificador simple (tabla \ref{tab:resultadosDecoSimple}). Tal es así, que tanto el $i_{eAvg}$ como el $i_{eMax}$ en algunos casos es mayor al doble de lo obtenido con en el decodificador simple. También se vuelve a observar como disminuye $i_{eAvg}$ a medida que crece el tamaño de la instancia del problema.

\section{Biased Random Key Genetic Algorithms}

En una primera instancia se implementa un BRKGA estándar. Dado una instancia de un problema, primero se genera la población inicial. Luego mientras no se cumpla la condición de parada, evolucionamos la población. Es decir creamos una nueva generación de soluciones a partir de la generación anterior como se explicó en la sección BRKGA ~(ver sección~\ref{sec:brkga}).

\bigskip

A continuación muestro el pseudocódigo de una vista macro general del algoritmo BRKGA implementado:

\bigskip

\begin{minipage}{\textwidth}
\begin{lstlisting} 
public Solution RunBrkga(ProblemManager problemManager)
{
    ProblemManager.InitializePopulation();

    while (!ProblemManager.StoppingRuleFulfilled())
        ProblemManager.EvolvePopulation();

    return ProblemManager.Population.GetMostProfitableSolution();
}
\end{lstlisting}
\end{minipage}

\bigskip

El objeto \textit{ProblemManager} es el orquestrador del BRKGA, se setea con un objeto \textit{Configuración} y el objeto \textit{PopulationGenerator}. Tiene acceso de forma indirecta, a través de \textit{PopulationGenerator}, de toda la información del problema (vehículos, clientes, tMax, etc.).

\subsection{Configuración} \label{sec:config}

A modo de poder testear distintas configuraciones del BRKGA, se creo un objeto \textit{Configuration} que setea todas las configuraciones que impactan en el resultado final del BRKGA. Este objeto es esencial para tunear el implementación de una forma rápida y ordenada. Al centralizar todas las variables que podrían impactar en resultado final, ganaba mucho tiempo al testear variaciones de mi implementación. Además, al estar centralizada toda la información variable se obtiene una lectura veloz del BRKGA que se está usando. En otras palabras incrementamos nuestra capacidad de monitoreo y control del desarrollo. A continuación el objeto \textit{Configuration} y sus propiedades:

\bigskip

\begin{minipage}{\textwidth}
\begin{lstlisting}
public class BrkgaConfiguration
{
	public string Description { get; }
	public int MinIterations { get; set; }
	public int MinNoChanges { get; set; }
	public int PopulationSize { get; set; }
	public decimal ElitePercentage { get; set; }
	public decimal MutantPercentage { get; set; }
	public int EliteGenChance { get; set; }
	public List<ILocalSearchHeuristic> Heuristics { get; set; }
	public int ApplyHeuristicsToTop { get; set; }
	public DecoderEnum DecoderType { get; set; }
	
	private void SetDescription();
}
\end{lstlisting}
\end{minipage}

\bigskip

\subsection{Descripción y codificación de las propiedades del objeto configuración}\label{sec:descrCongif}
Descripción de las propiedades del objeto Configuración:

\begin{itemize}
  \item \textbf{Description}: Es una especie de hash descriptivo de la instancia del objeto. Su funcionalidad es poder identificar rápidamente la configuración global del BRKGA. Solo puede ser seteado con el metodo SetDescription() que utiliza la clave y el valor de el resto de las propiedades.
  \item \textbf{MinIterations}: Clave \textbf{MI}. Valor entero utilizado en la función de corte. Cantidad mínima de generaciones que debe completar el BRKGA para finalizar. 
  \item \textbf{MinNoChanges}: Clave \textbf{MNC}. Valor entero utilizado en la función de corte. Cantidad de generaciones sin modificaciones del mejor beneficio necesario para cortar el algoritmo BRKGA.
  \item \textbf{PopulationSize}: Clave \textbf{PS}. Valor entero denota el tamaño de la población.
  \item \textbf{ElitePercentage}: Clave \textbf{EP}. Valor decimal en el intervalo $(0, 1)$ que determina el tamaño de la población elite. 
  \item \textbf{MutantPercentage}: Clave \textbf{MP}. Valor decimal en el intervalo $(0, 1)$ que determina el tamaño mínimo de la población mutante. 
  \item \textbf{EliteGenChance}: Clave \textbf{EGC}. Valor entero en el intervalo $(0, 100)$ que determina la probabilidad que tiene el alelo del padre elite, en transmitirse a su descendiente. 
  \item \textbf{Heuristics}: Clave \textbf{HEU}. Secuencia de algoritmos de búsquedas locales que se le aplicaran a la mejor solución de cada generación, a la cual no se le hayan aplicado las búsquedas locales aún. Se implementaron cuatro búsquedas locales (Su desarrollo sera explicado mas adelante en otra sección.):
	\begin{itemize}
		\item \textbf{Swap}: Valor \textbf{S}.
		\item \textbf{Insert}: Valor \textbf{I}.
		\item \textbf{2-Opt}: Valor \textbf{O}.
		\item \textbf{Replace}: Valor \textbf{R}.
	\end{itemize}  
  \item \textbf{ApplyHeuristicsToTop}: Clave \textbf{TOP}. Valor entero que denota la cantidad de soluciones a las cuales se les aplicaran las búsquedas locales.
  \item \textbf{DecoderType}: Clave \textbf{D}. Es una enumeración que determina el decodificador que se va a utilizar.
	\begin{itemize}
		\item \textbf{Simple}: Valor \textbf{S}.
		\item \textbf{Goloso}: Valor \textbf{G}.
	\end{itemize}  
\end{itemize}

\bigskip

El método \textit{SetDescription()} toma las tuplas de clave y valor de todas las propiedades del objeto \textit{Configuración} excepto \textit{Description} y lo concatena creando un \textit{string} intercalando con un separador.

\begin{minipage}{\textwidth}
\begin{lstlisting} 
public void SetDescription()
{ 
	var prop = Properties.Where(x => x.Name != "Description");
	var claveValores = prop.Select(p => p.Clave + "." + p.Valor);
	Description = string.Join(";", claveValores);
}
\end{lstlisting}
\end{minipage}


\begin{minipage}{\textwidth}
Luego leyendo la propiedad \textit{Description} podemos ver como esta configurado el BRKGA.

Ej: "MI.200;MNC.10;PZ.100;EP.0,3;MP.0,1;EGC.70;HEU.ISIRT;TOP.2;D.G"

\begin{itemize}
  \item MinIterations: 200
  \item MinNoChanges: 10
  \item PopulationSize: 100
  \item ElitePercentage: 0,3
  \item MutantPercentage: 0,1
  \item EliteGenChance: 70
  \item Heuristics: ISIRT. Que es la Secuencia Insert, Swap, Insert, Replace, 2-Opt.
  \item ApplyHeuristicsToTop: 2
  \item DecoderType: Decodificador Goloso
\end{itemize}
\end{minipage}

\subsection{Inicialización de la Población}

Utilizando \textit{PopulationSize} del objeto \textit{Configuration} seteo el tamaña de la población. Luego para generar la población inicial se generaran \textit{PopulationSize} vectores de enteros aleatorios de tamaño $\#clientes$ de la instancia del problema. Este conjunto de vectores se lo pasa como argumento al decodificador, quien genere un individuo por cada vector de enteros aleatorios.

\subsection{Condición de parada}

En un principio la condición de parada era simple, el bucle terminaba cuando iteraba una \textit{MinIterations} veces, seteado en el objeto \textit{Configurations}. Es decir que el bucle principal cortaba luego de evolucionar la población $MinIerations$ veces. Luego de analizar las últimas generaciones de la solución y ver que era frecuente que la mejor solución se había generado recientemente, agregue una condición de corte adicional. Ahora, para cortar ademas de la condición anterior, el beneficio de la mejor solución no debería haberse modificado durante las últimas \textit{MinNoChanges} generaciones. Es decir durante las últimas \textit{MinNoChanges} generaciones no debe haber aparecido una nueva mejor solución. \textit{MinNoChanges} es un entero que se setea en el objeto \textit{Configurations}.

\bigskip

\begin{minipage}{\textwidth}
\begin{lstlisting} 
public bool StoppingRuleFulfilled()
{ 
    return GenerationNum >= MinIterations && NoChanges();
}
private bool NoChanges()
{
	var currentProfit = CurrentBestSolution.GetProfit();
	return LastProfits.All(p => p == currentProfit);
}
\end{lstlisting}
\end{minipage}

\subsection{Evolución de la población}

Se toma la población y se ordenan sus individuos de forma descendente según su beneficio calculado con la función objetivo. Los mejores pasan a ser parte de la población de elite y el resto de la población no-elite. El tamaño de la población de elite depende de la propiedad \textit{ElitePercentage} del objeto \textit{Configuration}. Luego se generan individuos mutantes, su cantidad es un porcentaje de la población total seteado por la propiedad \textit{MutantPercentage}. Pasan a la nueva generación todos los individuos de la población de elite y se agregan los de la población mutante. Finalmente se completa la nueva generación emparentando individuos de la población de elite con individuos de la población no-elite. Los padres son elegidos al azar y el proceso de apareamiento se realiza como se describe en el la sección BRKGA ~(ver sección~\ref{sec:brkga}). Durante el apareamiento, no es tan extraño que se genere una solución idéntica a otra ya existente en la población. De modo de no repetir soluciones, antes de insertar el individuo resultante se verifica que no exista otra solución idéntica en la nueva generación. A continuación el pseudocódigo de la evolución de la población.

\bigskip

\begin{minipage}{\textwidth}
\begin{lstlisting}
public Population Evolve(Population population)
{
    var ordPopulation = population.GetOrderByMostProfitable();
    var elites = ordPopulation.Take(EliteSize);
    var nonElites = ordPopulation.Skip(EliteSize).Take(NonEliteSize);
    var mutatants = Generate(MutatansSize);
    var evolvedPopulation = new pop(elites, mutatants);
    while (evolvedPopulation.Size() < PopulationSize)
    {
	var anElite = GetRandomItem(elites);
	var aNoneElite = GetRandomItem(nonElites);
      var childSolution = Mate(anElite, aNoneElite);
	if (evolvedPopulation.Any(x => x.Equals(childSolution)))
		evolvedPopulation.Add(GenerateSolution());
      else
		evolvedPopulation.Add(childSolution);
    }
    return evolvedPopulation;
}
\end{lstlisting}
\end{minipage}

\begin{minipage}{\textwidth}
\begin{lstlisting}
private Solution Mate(Solution eliteP, Solution nonEliteP)
{
	var childRandomKeys = new List<RandomKey>();
	for (var index = 0; index < eliteP.RandomKeys.Count; index ++)
	{
		int key = 0;
		if(Random.Next(100) >= EliteGenChance)
			key = eliteP.RandomKeys[index].Key;
		else
			key = nonEliteP.RandomKeys[index].Key;
		var randomKey = new RandomKey(key, index);
		childRandomKeys.Add(randomKey);
	}
	return Decoder.Decode(childRandomKeys, ProblemInfo);
}
\end{lstlisting}
\end{minipage}

\bigskip

Como mencioné anteriormente, los individuos mutantes son individuos generados a partir de un vector de \textit{RandomKeys}, del mismo modo que la población inicial. Con el fin de mostrar lo simple que es la generación de un nuevo vector de \textit{RandomKeys}, presento el pseudocódigo del \textit{GenerateSolution} que al final termina llamando al método \textit{Decode} de alguno de los decodificador descrito anteriormente (puede ser cualquiera).

\bigskip

\begin{minipage}{\textwidth}
\begin{lstlisting}
private Solution GenerateSolution()()
{
	var randomKeys = new List<RandomKey>();
	for(i = 0; i < ProblemInfo.Clients.Length; i++)
	{
		var key = Random.Next(1000);
		var randomKey = new RandomKey(key, index);
		randomKeys.Add(randomKey)
	}
	return Decoder.Decode(randomKeys, ProblemInfo);
}
\end{lstlisting}
\end{minipage}

\bigskip

Verificar que dos soluciones son iguales tiene un costo muy bajo en BRKGA. Nosotros sabemos que dado un vector de \textit{RandomKeys}, al decodificarlo siempre obtenemos la misma solución. Por lo tanto para dos vectores de \textit{RandomKeys} cuyo orden de clientes que genere sea el mismo, el decodificador generará la misma solución. Luego no es necesario comparar las soluciones, nos es suficiente comparando el hash de cada soluciones y esto se puede hacer en $O(1)$. El hash de una solución, se calcula una sola vez cuando se construye la solución a partir de su vector de \textit{RandomKeys} y no es mas que una concatenación de los \textit{ClientId} de cada \textit{RandomKey} en el vector ordenados por la propiedad \textit{Key}, intercalados con un separador. La figura \ref{fig:codificacionDeSolucionParteDos} muestra un \textit{RandomKeys} y su hash correspondiente.Es decir, es el orden en que el decodificador toma los clientes para asignarlos a una ruta. Luego, cada vez que se obtiene una solución durante el método de \textit{crossover}, si ya existe un individuo con el mismo hash, se genera una solución mutante y continua el apareamiento de otros dos individuos. Decidí no reintentar el apareamiento entre los dos padres que generaron la solución repetida, porque consideré que la probabilidad de volver a generar nuevamente una solución existente es alta cuando ya sucedió una vez. Volver a intentar indefinidamente se traduce a un incremento del tiempo de ejecución. Luego tome esta decisión para optimizar el apareamiento y disminuir la cantidad de soluciones similares dentro de un mismo vecindario por generación.

\bigskip

\begin{minipage}{\textwidth}
\begin{lstlisting}
private string pseudoHash;
public string GetHash()
{
	if (!string.IsNullOrEmpty(pseudoHash))
		return pseudoHash;
		
	var ork = RandomKeys.OrderBy(r => r.Key)
	pseudoHash = string.Join("@", ork.Select(k => k.ClientId));
	return pseudoHash;
}
\end{lstlisting}
\end{minipage}

\bigskip

En una primera instancia se insertaban los individuos sin verificar que la existencia de un individuo idéntico en la población. Dado una población de soluciones no repetidas, la probabilidad de de generar una solución existente al evolucionar la población, es baja. Aún así, una vez que sucede, la probabilidad de generar otra más aumenta considerablemente ya que ahora hay mas probabilidades de utilizar padres idénticos. Si además la solución repetida se encuentra dentro del subconjunto de elite, la probabilidad aumenta aún más. Esto genera un efecto bola de nieve donde cada nueva generación tiene cada vez más individuos repetidos. Incluso he llegado al caso donde toda una población constituía de una única solución excepto por las soluciones mutantes. Esto reducía ampliamente la cantidad de soluciones diferentes exploradas, luego reducía fuertemente la frecuencia con la que una nueva mejor solución aparecía. Además si uno tiene varios individuos iguales en una solución, el algoritmo se vuelve menos eficiente ya que repite trabajo en donde obtiene los mismos resultados. Entonces el costo total de validar unicidad en la inserción, que conlleva un orden de complejidad $O(PopulationSize * NonElitePopulationSize)$, resulta muy bajo comparado con el costo de trabajar con múltiples soluciones repetidas.

\subsection{Resultados de la primer versión}

La primer versión del BRKGA para TOP no incluía el objeto de configuración y permitía insertar soluciones repetidas en una misma generación. Los resultados que mostraré a continuación corresponden con una segunda versión que no admitía repetidos y existía el objeto configuración. Se utilizo una configuración estándar sin búsquedas locales aún: 
\\ 'MI.250;MNC.10;PS.100;EP.0,3;MP.0,1;EGC.70;HEU.;TOP.0;MI.G' (ver sección~\ref{sec:descrCongif}).

\bigskip

\begin{center}
\begin{tabular}{ |c|c|c|c|c|c|c|c|c|c| } 
 \hline
$I$ & $\#N$ & $\#V$ & $tMax$ & $T_{avg}$ & $B_{max}$ & $B_{min}$ & $B_{avg}$ & $i_{eAvg}$ & $BTP_{max}$ \\
\hline
p2.2.k & 21 & 2 & 22.50 & 2977 & 260 & 240 & 249 & 0.91 & 275  \\
p2.3.g & 21 & 3 & 10.70 & 1990 & 145 & 145 & 145 & 1.00 & 145  \\
p3.4.p & 33 & 4 & 22.50 & 6482 & 450 & 430 & 438 & 0.78 & 560  \\
p5.3.x & 66 & 3 & 40.00 & 17908 & 660 & 610 & 635 & 0.41 & 1555  \\
p7.2.e & 102 & 2 & 50.00 & 8753 & 246 & 204 & 217 & 0.75 & 290  \\
p7.4.t & 102 & 4 & 100.00 & 31532 & 513 & 458 & 481 & 0.45 & 1077  \\
\hline
\end{tabular}
\end{center}

\bigskip

De estos primeros resultados podemos ver que el BRKGA puro sin otras heurísticas funciona muy bien para instancias de testeo pequeñas esta versión funcionaba tan bien como Chao, Golden y Wasil \cite{ChaoGoldenWasil} (CGW), Tang y Miller-Hooks \cite{TangMillerHooks} (TMH) y Archetti, Hertz, Speranza \cite{ArchettiHertzSperanza} (AHS). Esto se refleja en la instancia \textit{p2.3.k} que siempre se llegó a la mejor solución posible y en \textit{p2.2.k} donde el $i_eAvg$ supera el 0.90. Luego a medida que incrementa el tamaño de la instancia, disminuye el $i_eAvg$. Una observación que quiero destacar de estos resultados es sobre el $i_eAvg$ de la instancia \textit{p7.2.e}. Notar que tiene tantos nodos como \textit{p7.4.t} y sin embargo tiene un $i_eAvg$ ampliamente mayor. Esto seguramente sea por la diferencia en $tMax$, es 50 en vez de 100 reduciendo la combinatoria de soluciones posibles.


\bigskip

Como estos resultados no eran satisfactorios, tomé las dos instancias de este subconjunto con menor $i_{eAvg}$ y las utilice para testear distintas configuraciones. Probé múltiples variaciones del objeto configuración. A continuación el resultado de algunas de tales variaciones:

\bigskip


\begin{center}
\begin{tabular}{ |c|c|c|c|c|c|c|c|c|c|c|c| } 
 \hline
$I$ & $\#N$ & $\#V$ & $tMax$ & $C$ & $\#S$ & $T_{avg}$ & $B_{max}$ & $B_{min}$ & $B_{avg}$ & $i_{eAvg}$ & $BTP_{max}$ \\
\hline
p5.3.x & 66 & 3 & 40.00 & 1 & 10 & 60782 & 700 & 635 & 656 & 0.42 & 1555  \\
p5.3.x & 66 & 3 & 40.00 & 2 & 10 & 23363 & 660 & 620 & 636 & 0.41 & 1555  \\
p5.3.x & 66 & 3 & 40.00 & 3 & 10 & 22357 & 685 & 615 & 643 & 0.41 & 1555  \\
p5.3.x & 66 & 3 & 40.00 & 4 & 10 & 7311 & 555 & 475 & 498 & 0.32 & 1555  \\
p5.3.x & 66 & 3 & 40.00 & 5 & 10 & 54239 & 750 & 630 & 668 & 0.43 & 1555  \\
p7.4.t & 102 & 4 & 100.00 & 1 & 10 & 143760 & 542 & 472 & 506 & 0.47 & 1077  \\
p7.4.t & 102 & 4 & 100.00 & 2 & 10 & 42255 & 504 & 471 & 485 & 0.45 & 1077  \\
p7.4.t & 102 & 4 & 100.00 & 3 & 10 & 45952 & 542 & 463 & 488 & 0.45 & 1077  \\
p7.4.t & 102 & 4 & 100.00 & 4 & 10 & 11587 & 322 & 268 & 284 & 0.26 & 1077  \\
p7.4.t & 102 & 4 & 100.00 & 5 & 10 & 96642 & 509 & 478 & 491 & 0.46 & 1077  \\
\hline
\end{tabular}
\end{center}

\bigskip

Configuraciones: 
\begin{itemize}
  \item \textbf{C = 1}: MI.100;MNC.100;PS.500;EP.0,30;MP.0,05;EGC.70;HEU.;TOP.0;D.G
  \item \textbf{C = 2}: MI.150;MNC.30;PS.200;EP.0,25;MP.0,05;EGC.60;HEU.;TOP.0;D.G 
  \item \textbf{C = 3}: MI.150;MNC.70;PS.200;EP.0,30;MP.0,10;EGC.70;HEU.;TOP.0;D.G
  \item \textbf{C = 4}: MI.150;MNC.70;PS.200;EP.0,30;MP.0,10;EGC.70;HEU.;TOP.0;D.S
  \item \textbf{C = 5}: MI.250;MNC.50;PS.250;EP.0,15;MP.0,05;EGC.50;HEU.;TOP.0;D.G 
\end{itemize}

\bigskip

Como síntesis de estos resultados digo que la configuración básica poco influye en el beneficio final de la solución. En el caso de la instancia \textit{p5.3.x}, el $i_{eAvg}$ siempre se encuentra en el intervalo [0.41,0.43] y en en \textit{p7.4.t} el intervalo es [0.45,0.47]. Para ambas instancias hay una configuración que es claramente peor y es la configuración \textbf{C = 4} donde se utiliza el decodificar \textbf{simple} en vez del \textbf{goloso}. Luego claramente en esta versión del BRKGA el decodificador tiene gran impacto en el resultado final. Lamentablemente el resto de las configuraciones impacta muy poco en el beneficio total cuando la instancia del problema es grande (Mínima cantidad de iteraciones, mínima cantidad de iteraciones sin cambios, tamaño de la población, población elite, etc). Si impactan en el tiempo en que finaliza el algoritmo. Como no estaba del todo conforme con los resultados, decidí agregar algunas búsquedas locales para mejorar algunas soluciones entre cada iteración.

\bigskip

\section{Búsqueda local}

En pos de optimizar los resultados mencionados anteriormente se implementaron algunas búsquedas locales. La idea fue aplicar estas búsquedas algunas de las mejores soluciones de cada nueva generación. La cantidad de individuos a mejorar sería regida por el atributo \textit{ApplyHeuristicsToTop} del objeto \textit{Configuration}. En caso de que a la solución ya se le hubiese aplicado las búsquedas en una generación anterior, se aplican a la siguiente mejor solución. Esto puede suceder ya que las mejores soluciones pertenecen al conjunto de elite, y todos los individuos del conjunto de elite pasan directamente a la siguiente generación. La idea de implementar búsquedas locales la obtuve de el trabajo \textit{A guided local search metaheuristic for the team orienteering problem.} de Vansteenwegen et al. \cite{VansteenwegenSouffriauBergheOudheusden}, aunque es algo recurrente que encontré en varios trabajos previos de la literatura. Todas las búsquedas locales pueden modificar una solución ya sea para reducir su tiempo de recorrido o beneficio recolectado y la solución resultante es valida. Es decir se siguen respetando las restricciones de distancia máxima por vehículo, ningún cliente es visitado mas de una ves y la cantidad de vehículos se respeta. 

\subsection{Center of Gravity}

Para las búsquedas local \textit{Insert} y \textit{Replace} se deben tomar una lista de clientes a considerar con algún orden. Este orden es importante ya que queremos empezar por las mejores opciones. El orden de clientes que se utiliza es por su distancia al centro de gravedad (COG) de una ruta. A menor distancia, mayor prioridad tendrá el cliente. Implementé el calculo de COG de la forma que lo describen Vansteenwegen et al. \cite{VansteenwegenSouffriauBergheOudheusden}. La coordenada COG de una ruta se calcula con las siguientes formulas:

\begin{equation}
x_{cog} = (\sum_{\forall i \in ruta} x_i * B_i) / \sum_{\forall i \in ruta} B_i
\end{equation}

\begin{equation}
y_{cog} = (\sum_{\forall i \in ruta} y_i * B_i) / \sum_{\forall i \in ruta} B_i
\end{equation}

\bigskip

Donde $x_i$ e $y_i$ son las coordenadas de un cliente de la ruta y $B_i$ es su beneficio.
El calculo de COG tiene una complejidad de $O(ruta.Length)$. No es tan costoso, de todos modos como no quiero realizar cálculos innecesarios, el COG de una ruta solo se calcula cuando se necesita, es decir cuando la solución es seleccionada para ser mejorada. Se calcula una sola vez y cuando se modifica la ruta, actualizo el COG.

\bigskip

Sea $r$ una ruta:

\begin{equation}
r.x_{cog} =  \frac{\sum_{\forall i \in ruta} x_i * B_i}{\sum_{\forall i \in ruta} B_i}  = \frac{r.x_{cog.num}}{r.x_{cog.den}}
\end{equation}

\bigskip

Sea $r' = r.Remove(c_j)$ con $c_j$ cliente y $c_j \in r$:

\begin{equation}
r'.x_{cog} =  \frac{\sum_{\forall i \in ruta \wedge i \neq j} x_i * B_i}{\sum_{\forall i \in ruta \wedge i \neq j} B_i}  = \frac{r.x_{cog.num}-x_j*B_j}{r.x_{cog.den}-B_j}
\end{equation}

\bigskip

Sea $r'' = r.Add(c_k)$ con $c_k$ cliente y $c_k \notin r$:

\begin{equation}
r'.x_{cog} =  \frac{(\sum_{\forall i \in ruta} x_i * B_i) + x_k * B_k}{(\sum_{\forall i \in ruta} B_i) + B_k}  = \frac{r.x_{cog.num}+x_k*B_k}{r.x_{cog.den}+B_k}
\end{equation}

\bigskip

Luego actualizar el COG de una ruta al agregar ó remover un cliente tiene una complejidad de $O(1)$ si no perdemos los valores de $x_{cog.num}$ y $x_{cog.den}$ al calcular COG (Lo mismo aplica para la coordenada $y$).

\bigskip


\subsection{Swap}

El objetivo de esta búsqueda es encontrar e intercambiar clientes entre dos rutas distintas con el fin de disminuir la suma de las distancias recorridas de ambas rutas, respetando la restricción de distancia máxima por vehículo. Es decir dados $v_a$, $v_b$ vehículos y sus respectivas rutas $r_a$, $r_b$, se puede realizar un \textit{swap} entre sus rutas si existe un cliente $c_{a_i}$ en la ruta de $r_a$ y otro cliente $c_{b_j}$ en $r_b$ tal que agregando $c_{a_i}$ en alguna posición de $r_b$ y agregando $c_{b_j}$ en alguna posición de $r_a$, son validas las siguientes formulas:

\begin{equation*}
r_a.Dist + r_b.Dist < r_a'.Dist + r_b'.Dist \nonumber
\end{equation*}

\begin{equation*}
r_a'.Dist \leq v'_a.tMax
\end{equation*}

\begin{equation*}
r_b'.Dist \leq v'_b.tMax
\end{equation*}

Al aplicar esta búsqueda a una solución, para todo par de rutas se ejecuta el método \textit{SwapDestinationsBetween}. Por lo tanto, este método sera llamado $n * (n-1) / 2$, siendo $n$ la cantidad de rutas en la solución. \textit{SwapDestinationsBetween} prueba cada cliente de la ruta $a$ con cada cliente de la ruta $b$, y si efectivamente conviene hacer un \textit{swap}, lo realiza. Luego continua probando si conviene intercambiar otro par de clientes entre las mismas rutas. De modo de no estar cambiando múltiples veces un mismo cliente entre dos rutas en una misma ejecución de \textit{SwapDestinationsBetween}, cuando se cambia de ruta a un cliente, se lo agrega en una lista de clientes prohibidos para hacer intercambiar hasta que termine la ejecución actual de \textit{SwapDestinationsBetween}. Esta búsqueda local no mejora el beneficio total de una solución, lo que hace es disminuir la distancia recorrida de alguna ruta, aumentando la probabilidad de encontrar algún cliente no visitado que se pueda insertar en alguna de las rutas modificadas.

\bigskip

\begin{minipage}{\textwidth}
\begin{lstlisting}
// Dentro de clase SwapHeuristic
public void ApplyHeuristic(Solution solution)
{
	var changed = false;
	var combinations = GetCombinationsFor(solution.Vehicles.Count);
	foreach (var combination in combinations)
	{
		var v1 = solution.Vehicles[combination.Left];
		var v2 = solution.Vehicles[combination.Right];
		changed = changed || SwapDestinationsBetween(v1, v2);
	}
	if(changed)
		solution = Encoder.UpdateRandomKeys(solution);
}
\end{lstlisting}
\end{minipage}

\begin{minipage}{\textwidth}
\begin{lstlisting}
public bool SwapDestinationsBetween(Vehicle v1, Vehicle v2)
{
	var changed = false;
	var v1Bans = new Dictionary<int, bool>();
	var v2Bans = new Dictionary<int, bool>();
	for (var i = 0; i < v1.Route.RouteLenght(); i++)
	{
		if(v1Bans.ContainsKey(i)) 
			continue;
		for (var j = 0; j < v2.Route.RouteLenght(); j++)
		{
			if (v2Bans.ContainsKey(j)) 
				continue;
			if (!Swaps(i, j, ref leftRoute, ref rightRoute)) 
				continue;
			changed = true;
			v1Bans.Add(i, true);
			v2Bans.Add(j, true);
			break; // Para que cambie i
		}
	}
	return changed;
}
\end{lstlisting}
\end{minipage}

\bigskip

El orden de complejidad del método \textit{ApplyHeuristic} de la clase \textit{SwapHeuristic} es:

\begin{equation*}
O((n * (n-1) / 2 ) * clientes/n * clientes/n) \approx O(clientes^2/2)
\end{equation*}

\subsection{Insert}

El objetivo de esta búsqueda local es encontrar una posición en alguna ruta para un cliente no visitado sin sobrepasar el limite de distancia máxima de la ruta. Básicamente para cada vehículo y cada cliente no visitado se busca en que posición se debe insertar el cliente de forma tal que minimice el incremento de distancia recorrida. Si la distancia resultante es menor a la distancia máxima del vehículo, se inserta el cliente en tal posición. En caso contrario, no se inserta y se prueba con el siguiente cliente no visitado. El orden en que se toman los clientes no visitados es según su distancia al COG de la ruta a optimizar, de forma ascendente.

\begin{minipage}{\textwidth}
\begin{lstlisting}
// Dentro de clase InsertHeuristic
public void ApplyHeuristic(Solution solution)
{
	// Lista de los clientes no visitados
	var changed = false;	
	var uClients = solution.GetUnvistedClients;	
	var vehicles = solution.Vehicles;
	foreach (var vehicle in vehicles)
	{
		vehicle.Route.ActivateCog();
		uClients = uClients.OrderBy(x => vehicle.DistanceToCog(x));	
		for (var index = 0; index < uClients.Count; index++)
		{
			var res = AnalizeInsert(solution, vehicle, uClients[index]);
			if (res.CanBeInserted)
			{
				vehicle.AddDestinationAt(uClients[index], res.BestPosition);
				uClients.Remove(uClients[index]);
				changed = true;
			}
		}
	}
	if(changed)
		solution = Encoder.UpdateRandomKeys(solution);
}
\end{lstlisting}
\end{minipage}

\bigskip

Como mencioné en la implementación de COG, solo se utiliza cuando es necesario, luego para cada vehículo lo primero que hace es activar el COG. Segundo, por cada cliente no visitado hasta el momento se analiza el \textit{insert}. El método \textit{AnalizeInsert} retorna un objeto que tiene seteado dos campos importantes. Un campo de tipo \textit{bool} que denota que el cliente puede ser insertado o no en el vehículo consultado. Y otro campo que tiene la posición donde se debe insertar, en caso de poder insertarse. En caso de poder insertar el cliente, se inserta y se actualiza el COG de la ruta, y se remueve el cliente de la lista de no visitados. El orden de complejidad del método \textit{ApplyHeuristic} de la clase \textit{InsertHeuristic} es: 

\begin{equation*}
0(vehiculos * clientesNoVisitados * mediaClientesEnRuta)
\end{equation*}

\subsection{2-opt}

El algoritmo \textit{2-opt} es un simple algoritmo de búsqueda local propuesto por Croes \cite{Croes}. El fin es buscar un orden alternativo de los clientes visitados en una dentro de una misma ruta, de modo que disminuya la distancia recorrida de la misma. Es decir, un \textit{swap} de posiciones de dos clientes dentro de una misma ruta.

\begin{minipage}{\textwidth}
\begin{lstlisting}
// Dentro de clase 2-opt
public void ApplyHeuristic(Solution solution)
{
	var index = 0;
	var changed = false;	
	var vehicles = solution.Vehicles;	
	while (index < vehicles.Count)
	{
		var currentDistance = vehicles[index].Route.GetDistance();
		changed = changed || Do2OptSwap(vehicles[index]);
		index++;
	}
	if(changed)
		solution = Encoder.UpdateRandomKeys(solution);
}
\end{lstlisting}
\end{minipage}

\begin{minipage}{\textwidth}
\begin{lstlisting}
private bool Do2OptSwap(Vehicle vehicle)
{
	var changed = false;	
	var combinations = GetCombinationsFor(vehicle.Route.GetDistance());
	var index = 0;
	while (index < combinations.Count)
	{
		var position1 = combinations[index].Item1 - 1;
		var position2 = combinations[index].Item2 - 1;
		var swaped = vehicle.Route.SwapIfImprovesDistance(position1, position2);
		if (!swaped)
			index++;
		changed = true;
		index = 0;
	}
	return changed;
}
\end{lstlisting}
\end{minipage}

\bigskip

Básicamente a cada vehículo le aplica el \textit{2-opt}. El método \textit{Do2OptSwap} primero obtiene una lista de las permutaciones posibles. Luego por cada permutación intenta hacer un \textit{swap} dentro de la ruta. Si el \textit{swap} se realiza, vuelve a empezar desde el principio ya que ese cambio puede generar nuevos cambios. Como el \textit{swap} solo sucede cuando la nueva distancia es estrictamente menor, el bucle siempre termina ya que una ruta no puede estar mejorando infinitamente. Este algoritmo tiene un orden de complejidad $0(vehiculos * mediaClientesEnRuta  * (mediaClientesEnRuta - 1) / 2) ~ 0 (vehiculos * mediaClientesEnRuta^2 / 2)$.

\subsection{Replace Simple}

Esta búsqueda tiene como objetivo intercambiar un cliente no visitado por uno visitado de una ruta de modo que aumente el beneficio de la ruta. Del mismo modo que la heuristica insert, los clientes no visitados se toman en orden según su distancia al COG de la ruta, empezando por los más cercanos.

\begin{minipage}{\textwidth}
\begin{lstlisting}
// Dentro de la clase ReplaceHeuristicas
public void ApplyHeuristic(Solution solution)
{	
	var vehicles = solution.Vehicles;
	var changed = false;	
	foreach (var vehicle in vehicles)
		changed = changed || Replace(solution, vehicle);
	if(changed)
		solution = Encoder.UpdateRandomKeys(solution);
}
\end{lstlisting}
\end{minipage}

\begin{minipage}{\textwidth}
\begin{lstlisting}
private bool Replace(Solution solution, Vehicle vehicle)
{
	var unvisited = solution.GetCurrentUnvistedDestination;
	var changed = false;
	vehicle.Route.ActivateCog();
	uClients = uClients.OrderBy(x => vehicle.DistanceToCog(x));	

	foreach (var client in uClients)
	{
		var res = AnalizeInsert(solution, vehicle, client);
		vehicle.AddDestinationAt(destination, res.BestInsertPosition);
		if (!res.CanBeInserted)
		{
			var removedClient = RemoveWorstOrDefault(vehicle, client);
			changed = changed || removedClient.Id != client.Id;
		}
		else
			changed = true;
	}
	return changed;
}
\end{lstlisting}
\end{minipage}

\bigskip

El \textit{Replace Simple} es muy similar al \textit{Insert} y esto se refleja en el pseudocódigo. Ante un cliente no visitado, lo primero que hace es analizar si se puede insertar y cual es la mejor posición donde se puede insertar, llamando al método \textit{AnalizeInsert}. Luego sin siquiera verificar si realmente se puede insertar, lo inserta en la posición que menos incrementa la distancia de la ruta. Este es el único momento de toda la implementación donde puede existir una solución invalida. Después de insertarlo se fija si realmente se podía insertar. En caso afirmativo, continua con el siguiente cliente. En caso contrario debe quitar un cliente. Para esto, crea un conjunto de clientes tales que cada uno de ellos tiene un beneficio menor o igual al del cliente insertado. Dentro de este conjunto se selecciona al cliente que al quitarlo de la ruta del vehículo, minimice la distancia de la ruta resultante. Como el cliente insertado pertenece al conjunto del cual se removerá un cliente, en el peor de los casos se removió el mismo cliente que se insertó, lo que significa que no se incremento el beneficio ni se disminuyo la distancia de la ruta. Cualquier otro cliente que se remueva de la ruta significará que se efectuó un \textit{replace} y aumento el beneficio total de la ruta ó, muy de vez en cuando, el beneficio no aumento pero se disminuyo la distancia de la ruta. El \textit{Replace Simple} tiene una complejidad de $O(vehiculos * clientesNoVisitados * mediaClientesEnRuta * 2)$. Llamé a esta búsqueda \textit{Replace Simple} por que no considera el caso donde se puede reemplazar un clientes visitado por varios clientes no visitados. Ademas, por mas que busca incrementar el beneficio de la ruta, en el momento de seleccionar uno de varios candidatos a ser removido, remueve aquel que disminuya en mayor medida la distancia de la ruta resultante.

\subsection{Replace Multiple}

El \textit{Replace Multiple} se diferencia del \textit{Replace Simple} en dos aspectos. El primer diferencia es que permite reemplazar varios clientes visitados por un cliente no visitado. La segunda diferencia es que dentro de todas sus opciones para reemplazar, selecciona aquella que maximice el beneficio. El \textit{Replace Multiple} tiene una complejidad algorítmica mayor al \textit{Replace Simple} ya que explora todas las opciones que explora el \textit{Replace Simple} y sus combinaciones. La segunda diferencia la agregue con el objetivo de diferenciar, aún más, el conjunto de soluciones exploradas por cada \textit{Replace}.

\bigskip

Al momento de seleccionar los clientes a remover, el \textit{Replace Multiple} crea un conjunto de conjuntos de clientes donde la sumatoria de beneficios de cada conjunto de clientes es menor o igual al beneficio del cliente insertado. Luego elimina los conjuntos de clientes que al eliminarlos del recorrido, la distancia de la ruta resultante sigue siendo mayor a la distancia máxima permitida. Dentro de los conjuntos restantes, se selecciona aquel de menor beneficio total. Nuevamente, en el peor de los casos se remueve al cliente insertado.

\bigskip

El \textit{Replace Multiple} mejoro considerablemente el $i_{eAvg}$ en instancias grandes ya que explora muchas mas opciones que el \textit{Replace Simple} y prioriza el beneficio sobre la distancia. Su complejidad aumenta bastante ya que el conjunto de conjuntos de clientes en el peor de los casos es de $2^n-1$, siendo $n$ la cantidad de clientes en la ruta. Sería el tamaño del conjunto de partes de clientes visitados restando el conjunto vacío. De todos modos es difícil que se de este caso, ya que para que suceda el beneficio del cliente insertado debe ser mayor o igual a la sumatoria de los beneficios del resto de los clientes en la ruta.

\subsection{Encoder}

Agregar búsquedas locales entre generación de poblaciones conlleva un problema que debe resolverse. Al mejorar la solución, se modifican sus rutas. Ahora bien, si no se actualizamos su genética acorde a los cambios realizados a la solución, es decir su \textit{RandomKeys}, sus descendientes heredarán los genes que generan una solución no optimizada por las búsquedas locales.

\begin{equation*}
ApplyHeuristic(s) \neq Decoder.Decode(s.RandomKeys, ProblemInfo)
\end{equation*}

Para solucionar esto se debe modificar el vector aleatorio de enteros, \textit{RandomKeys}, de la solución mejorada de modo que al decodificar tal vector aleatorio de enteros, genere la solución modificada. Como mencioné en el sección del Decodificador (ver sección~\ref{sec:ordenDeco}), los clientes se ordenan de forma ascendente por la propiedad \textit{Key} del objecto \textit{RandomKey} asociado según la propiedad \textit{ClientId}. Luego el primer cliente con el que trabaja el decodificador, es el cliente con menor valor de \textit{Key}. Algo que no mencioné sobre la implementación de los decodificadores es que el primer vehículo por el que empieza es por el de menor \textit{Id} ya que los ordena por su \textit{Id} de forma ascendente. Los vehículos son indistinguibles al tener el mismo \textit{tMax} en el benchmark de instancias de problemas. De todos modos ahora debo respetar la decisión que tomé en el desarrollo de los decodificadores. Por lo tanto tomo el primer cliente de la ruta del vehículo con menor \textit{Id} y a ese cliente le voy a asociar el {RandomKey} que tenga el menor \textit{Key}. Así, cuando el decodificador inicie, lo primero que hará es tomar este cliente e intentará adjudicárselo al primer vehículo, que justamente será el de menor \textit{Id}. Luego tomaré el segundo cliente del mismo vehículo y le asignare el segundo \textit{RandomKey} de menor \textit{Key}. Y así sucesivamente, hasta tener mapeados todos los clientes del primer vehículo con su nuevo \textit{RandomKey}. Luego repito el procedimiento con los clientes del siguiente vehículo ordenados por \textit{Id} ascendentemente. Finalmente, no tendré mas vehículos y quedará un resto de clientes no visitados a los cuales le tengo que asociar algún \textit{RandomKey}. A estos clientes podría asignarle cualquier \textit{RandomKey}. Aún así, en pos de disminuir los cambios genéticos sobre el individuo, les asigne un \textit{RandomKey} tal que entre ellos mantengan el mismo orden que tenían antes de la mejora. Es decir, dentro de los clientes no visitados, el cliente que previamente tenia el \textit{RandomKey} con menor \textit{Key}, le asigne el \textit{RandomKey} de menor \textit{Key} que había disponible.  Este proceso puede verse en la figura \ref{fig:codificacionDeSolucionUno} \ref{fig:codificacionDeSolucionDos}.

\bigskip

\begin{figure}[h]
	\caption{Como se mejora una solución}
	\centering
	\includegraphics[width=14cm]{codificacionDeSolucionParteUno}
	\label{fig:codificacionDeSolucionUno}
\end{figure}

\begin{figure}[h]
    \caption{Este es el \textit{RandomKeys} corregido y su hash luego que la solución de la figura \ref{fig:codificacionDeSolucionUno} fue mejorada con una búsqueda local.}
    \centering
    \includegraphics[width=14cm]{codificacionDeSolucionParteDos}
    \label{fig:codificacionDeSolucionDos}
\end{figure} 


\bigskip

Ahora bien, digamos que existe un escenario donde el decodificador se encuentra trabajando con un \textit{RandomKeys} que fue generado por el codificador y sucede lo siguiente. Al agregar al último cliente de la primer ruta, el decodificador intentará agregar a la primer ruta al resto de los clientes y supongamos que efectivamente encuentra uno. Cuando vi la posibilidad de este escenario, decidí agregar unos delimitadores de modo que si el decodificador se encuentra con uno, siempre cambie de vehículo. Estos delimitadores son modelados por la propiedad \textit{ForceVehicleChangeAfterThis}, con la que extendí al objeto \textit{RandomKey}. De este modo el decodificador, luego de utilizar el \textit{RandomKey}, se fija si \textit{ForceVehicleChangeAfterThis} es \textit{true} y si lo es, deja de intentar agregar clientes a la ruta del vehículo actual. Los delimitadores no son heredados a los descendientes. Estos delimitadores me aseguran la ecuación \ref{eq:reversibilidad} sea válida.

\begin{equation} \label{eq:reversibilidad}
ApplyHeuristic(s) = Decoder.Decode(s.RandomKeys, ProblemInfo)
\end{equation}

\bigskip

En caso de no tener los delimitadores, como dije antes, una ruta podría tener un cliente extra, que para fines del algoritmo, no es malo. Al agregar un cliente, hay dos opciones. La primera es que el cliente perteneciera al subconjunto de clientes que no estaba visitado. En este caso aumentaría el beneficio total. Pero para que esto suceda, el algoritmo de \textit{Insert} no debería haber funcionado correctamente ó no fue la última en aplicarse. En caso de que el cliente perteneciere a otro vehículo, el beneficio total no se modifica. El peor escenario es que este segundo vehículo se quede con el cliente de un tercer vehículo, sucediendo un especie de cambios encadenados de clientes entre un subconjunto de vehículos sin que decremente el beneficio total. Luego por mas que tomé la decisión de agregar los delimitadores, considero que ambas opciones eran igual de buenas considerando solamente la función objetivo. Agregando los delimitadores, aseguro la valides de la ecuación \ref{eq:reversibilidad}.

\bigskip

A continuación el pseudocodigo del algoritmo que actualiza el \textit{RandomKeys} de una solución mejorada:

\begin{minipage}{\textwidth}
\begin{lstlisting}
public static Solution UpdateRandomKeys(Solution s);
{
	var randomKeys = s.GetOrderedRandomKeys();
	// Todas las keys ordenadas ascendente
	var keys = randomKeys.Select(k => k.Key).ToList();
	var ClientIds = new List<int>();
	// Get ClientId from Visited Clients
	foreach (var r in s.Routes)
	{
		var d = r.GetDestinations();
		var rci = d.Select(d => d.ClientId);
		ClientIds.AddRange(rci);
	}
	// Get ClientId from Unvisited Clients
	var uClientIds = GetUnvisitedClientIds(randomKeys, newRoutes);
	ClientIds.AddRange(uClientIds);

	// Hay un break por cada cantidad de clientes en ruta 
	var breaks = new Queue(newRoutes.Select(r => r.ClientsCount));

	var newRandomKeys = new List<RandomKey>();
	var endRoute = false;
	var acumBreak = 0;
	for (var index = 0; index < keys.Count; index++)
	{
		if (breaks.Count > 0)
		{		
			endRoute = index + 1 == (int)breaks.Peek() + acumBreak;
			if (endRoute)
				acumBreak += (int)breaks.Dequeue();
		}		
		var randomKey = new RandomKey()
		{
			Key = keys[index],
			ClientId = ClientIdes[index],
			ForceVehicleChangeAfterThis = endRoute
		};
		newRandomKeys.Add(randomKey);
	}
	s.SetRandomKeys(newRandomKeys);
	return s;
}
\end{lstlisting}
\end{minipage}

\subsection{Orden de ejecución de las búsquedas locales}

Cuando se crea una instancia de mi algoritmo BRKGA, se setea una lista de búsquedas locales. En el momento que se realicen las búsquedas locales a una determinada solución, se ejecutaran todas las búsquedas locales de tal lista en el mismo orden que se encuentran en la lista. Por ejemplo, si $lista = (Swap, Insert, 2-Opt, Insert)$, entonces primero se aplicara \textit{Swap}, seguido de \textit{Insert} y finalmente \textit{Replace Multiple}. Esto me permite probar múltiples combinaciones de búsquedas locales modificando solamente una lista. La lista puede contener búsquedas repetidas, por ejemplo $lista = (Swap, Insert, 2-Opt, Insert)$. El orden en que se ejecutan las búsquedas locales tiene un impacto fuerte sobre la solución final generada. Esta lista la agregue al objeto configuración del BRKGA.

\bigskip

Con el objetivo de encontrar la mejor secuencia de búsquedas locales a aplicar, generé múltiples instancias de mi implementación con distintas listas de búsquedas locales. Cada una de estas instancias la ejecute diez veces y persistí los resultados. Todas las instancias comparten los mismos valores en el resto de su configuración, de forma que los resultados solo varíen por las búsquedas locales aplicadas. La configuración básica que comparten es: MI.200;MNC.50;PS.150;EP.0,3;MP.0,1;EGC.70;TOP.2.

\bigskip

Recordando los códigos de las búsquedas locales: 
\begin{itemize}
  \item \textbf{I}: Insert (Cliente no visitado)
  \item \textbf{Rs}: Replace Simple (Cliente no visitado por uno visitado)
  \item \textbf{Rm}: Replace Mutiple (Cliente no visitado por uno o varios visitado/s)
  \item \textbf{0}: 2-Opt (Swap dentro de una misma ruta)
  \item \textbf{S}: Swap (Swap entre dos rutas distintas)
\end{itemize}

\bigskip

\begin{table}
\begin{tabular}{ |c|c|c|c|c|c|c|c|c|c|c|c| } 
\hline
$I$ & $\# N/V/tMax$ & Orden & D & $t_{avg}$ & $B_{min}$ & $B_{avg}$ & $B_{max}$ & $i_{eMed}$ & $Best$ \\
\hline
p2.2.k & 21/2/22.50 & IRsRmOS & G & 4002 & 270 & 271 & 275 & 0.99 & 275 \\
p2.2.k & 21/2/22.50 & SIORsSORm & G & 4118 & 270 & 272 & 275 & 0.99 & 275 \\
p2.2.k & 21/2/22.50 & SIORsSORm & S & 2613 & 270 & 272 & 275 & 0.99 & 275 \\
p2.2.k & 21/2/22.50 & SOIRsRm & G & 3904 & 270 & 273 & 275 & 0.99 & 275 \\
p2.2.k & 21/2/22.50 & SOIRsRm & S & 2294 & 270 & 274 & 275 & 1.00 & 275 \\
p2.2.k & 21/2/22.50 & SOISOIRsRm & G & 4089 & 270 & 273 & 275 & 0.99 & 275 \\
p2.3.g & 21/3/10.70 & IRsRmOS & G & 2181 & 145 & 145 & 145 & 1.00 & 145 \\
p2.3.g & 21/3/10.70 & SIORsSORm & G & 2293 & 145 & 145 & 145 & 1.00 & 145 \\
p2.3.g & 21/3/10.70 & SIORsSORm & S & 1880 & 145 & 145 & 145 & 1.00 & 145 \\
p2.3.g & 21/3/10.70 & SOIRsRm & G & 2649 & 145 & 145 & 145 & 1.00 & 145 \\
p2.3.g & 21/3/10.70 & SOIRsRm & S & 1777 & 145 & 145 & 145 & 1.00 & 145 \\
p2.3.g & 21/3/10.70 & SOISOIRsRm & G & 2765 & 145 & 145 & 145 & 1.00 & 145 \\
p3.4.p & 33/4/22.50 & IRsRmOS & G & 10816 & 530 & 542 & 550 & 0.97 & 560 \\
p3.4.p & 33/4/22.50 & SIORsSORm & G & 11438 & 540 & 553 & 560 & 0.99 & 560 \\
p3.4.p & 33/4/22.50 & SIORsSORm & S & 4760 & 550 & 558 & 560 & 1.00 & 560 \\
p3.4.p & 33/4/22.50 & SOIRsRm & G & 10723 & 540 & 550 & 560 & 0.98 & 560 \\
p3.4.p & 33/4/22.50 & SOIRsRm & S & 4618 & 550 & 555 & 560 & 0.99 & 560 \\
p3.4.p & 33/4/22.50 & SOISOIRsRm & G & 11620 & 550 & 558 & 560 & 1.00 & 560 \\
p5.3.x & 66/3/40.00 & IRsRmOS & G & 35470 & 1455 & 1471 & 1490 & 0.95 & 1555 \\
p5.3.x & 66/3/40.00 & SIORsSORm & G & 37699 & 1485 & 1495 & 1525 & 0.96 & 1555 \\
p5.3.x & 66/3/40.00 & SIORsSORm & S & 16790 & 1485 & 1497 & 1515 & 0.96 & 1555 \\
p5.3.x & 66/3/40.00 & SOIRsRm & G & 29260 & 1485 & 1506 & 1525 & 0.97 & 1555 \\
p5.3.x & 66/3/40.00 & SOIRsRm & S & 12601 & 1490 & 1508 & 1535 & 0.97 & 1555 \\
p5.3.x & 66/3/40.00 & SOISOIRsRm & G & 34053 & 1485 & 1502 & 1515 & 0.97 & 1555 \\
p7.2.e & 102/2/50.00 & IRsRmOS & G & 13134 & 290 & 290 & 290 & 1.00 & 290 \\
p7.2.e & 102/2/50.00 & SIORsSORm & G & 13259 & 290 & 290 & 290 & 1.00 & 290 \\
p7.2.e & 102/2/50.00 & SIORsSORm & S & 7500 & 290 & 290 & 290 & 1.00 & 290 \\
p7.2.e & 102/2/50.00 & SOIRsRm & G & 12695 & 290 & 290 & 290 & 1.00 & 290 \\
p7.2.e & 102/2/50.00 & SOIRsRm & S & 6828 & 290 & 290 & 290 & 1.00 & 290 \\
p7.2.e & 102/2/50.00 & SOISOIRsRm & G & 13658 & 290 & 290 & 290 & 1.00 & 290 \\
p7.4.t & 102/4/100.00 & IRsRmOS & G & 60299 & 984 & 1013 & 1034 & 0.94 & 1077 \\
p7.4.t & 102/4/100.00 & SIORsSORm & G & 68191 & 1006 & 1029 & 1047 & 0.96 & 1077 \\
p7.4.t & 102/4/100.00 & SIORsSORm & S & 37733 & 1019 & 1037 & 1063 & 0.96 & 1077 \\
p7.4.t & 102/4/100.00 & SOIRsRm & G & 63010 & 1023 & 1033 & 1051 & 0.96 & 1077 \\
p7.4.t & 102/4/100.00 & SOIRsRm & S & 31241 & 1020 & 1035 & 1050 & 0.96 & 1077 \\
p7.4.t & 102/4/100.00 & SOISOIRsRm & G & 67730 & 1012 & 1030 & 1052 & 0.96 & 1077 \\
\hline
\end{tabular}
\caption{Resultados de distintos ordenes de búsquedas locales.}
\label{tab:secuenciaBusqueda}
\end{table}


En la tabla \ref{tab:secuenciaBusqueda}, se pueden observar los resultados de variar el orden en que se ejecutan las búsquedas locales. Claramente el peor orden de búsquedas locales es IRsRmOS (\textit{Insert}, \textit{Replace Simple}, \textit{Replace Multiple}, \textit{2-Opt}, \textit{Swap}). Esto sucede porque \textit{Insert} y \textit{Replace} intentan agregar mas clientes o intercambiar por clientes mas rentables mejorando el beneficio de la ruta. Mientras que \textit{2-Opt} y \textit{Swap} hacen un reordenamiento de la secuencia en que se visitan los clientes seleccionados, luego minimizan la distancia recorrida de una ruta. Al ejecutar primero las búsquedas que incrementan el beneficio y luego las que decrementan la distancia recorrida, no hacemos uso de la distancia disminuida por \textit{2-Opt} y \textit{Swap}.

\bigskip

Luego el mejor orden según estos resultados, fue SIORSOR. Notar que repito búsquedas en esta secuencia, en una primera impresión parece redundante pero no lo es. Por ejemplo, la primera vez que se aplica \textit{2-Opt} se hace luego de un \textit{Insert} que utiliza toda la distancia disponible y la segunda vez que se aplica el \textit{2-Opt} es posterior de un \textit{Swap}.

\bigskip

Sobre $T_{avg}$, notar entre la configuración 2 y 3 el tiempo puede llegar a ser más del doble y la única diferencia es que se uso el decodificador simple versus el goloso. Esto lo logra con un $i_eAvg$ prácticamente igual en todas las instancias. Lo mismo podemos observar entre la configuración 4 y 5. Por lo tanto, habiendo agregado las búsquedas locales, el decodificador goloso no mejora el beneficio final y el decodificador simple reduce el tiempo de ejecución. Por este motivo para los resultados finales utilicé el decodificar simple.

\bigskip

Estos resultados me parecieron muy buenos ya que en dos de las seis instancias se llega a la mejor solución conocida y en los resultados de las otras cuatro instancias son competitivos con los trabajos previos de la literatura. Por eso decidí correr mi algoritmo para el resto de las instancias del benchmarck.


